data: {"step":0,"timestamp":"2025-09-15T19:26:53.457866+00:00","type":"checkpoint","payload":{"config":{"configurable":{"checkpoint_ns":"","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_id":"1f09269e-f6c8-6e8f-8000-61b81d860490"}},"parent_config":{"configurable":{"checkpoint_ns":"","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_id":"1f09269e-f6c0-69e6-bfff-d88e995570cc"}},"values":{"messages":[{"content":"hi","additional_kwargs":{},"response_metadata":{},"type":"human","name":null,"id":"7aae7cba-94b6-4218-8747-4f0f66a34000","example":false}],"documents":[]},"metadata":{"source":"loop","step":0,"parents":{}},"next":["create_research_plan"],"tasks":[{"id":"5e333532-4443-c672-d930-ecf3120c85cd","name":"create_research_plan","interrupts":[],"state":null}],"checkpoint":{"checkpoint_id":"1f09269e-f6c8-6e8f-8000-61b81d860490","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":""},"parent_checkpoint":{"checkpoint_id":"1f09269e-f6c0-69e6-bfff-d88e995570cc","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":""}}}

event: debug
data: {"step":1,"timestamp":"2025-09-15T19:26:53.457897+00:00","type":"task","payload":{"id":"5e333532-4443-c672-d930-ecf3120c85cd","name":"create_research_plan","input":{"messages":[{"content":"hi","additional_kwargs":{},"response_metadata":{},"type":"human","name":null,"id":"7aae7cba-94b6-4218-8747-4f0f66a34000","example":false}],"router":{"type":"general","logic":""},"steps":[],"documents":[],"answer":"","query":""},"triggers":["branch:to:create_research_plan"]}}

event: messages/metadata
data: {"run--27fb1bde-8c18-4056-8549-baa92acf003c":{"metadata":{"created_by":"system","from_studio":true,"assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","LANGGRAPH_API_URL":"https://chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","run_attempt":1,"langgraph_version":"0.6.6","langgraph_api_version":"0.4.3","langgraph_plan":"enterprise","langgraph_host":"saas","langgraph_api_url":null,"k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","langgraph_step":1,"langgraph_node":"create_research_plan","langgraph_triggers":["branch:to:create_research_plan"],"langgraph_path":["__pregel_pull","create_research_plan"],"langgraph_checkpoint_ns":"create_research_plan:5e333532-4443-c672-d930-ecf3120c85cd","checkpoint_ns":"create_research_plan:5e333532-4443-c672-d930-ecf3120c85cd","ls_provider":"anthropic","ls_model_name":"claude-3-5-haiku-20241022","ls_model_type":"chat","ls_temperature":0.0,"ls_max_tokens":1024,"tags":["langsmith:nostream"]}}}

event: messages/partial
data: [{"content":[],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":""}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\""}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":[""]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the us"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the us"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and "}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and "]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask abo"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask abo"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about t"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about t"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about their specific"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about their specific"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about their specific LangCha"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about their specific LangCha"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about their specific LangChain-related"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about their specific LangChain-related"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about their specific LangChain-related quest"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about their specific LangChain-related quest"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about their specific LangChain-related question or issue"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about their specific LangChain-related question or issue"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about their specific LangChain-related question or issue\"]}"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about their specific LangChain-related question or issue"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","input":{},"name":"Plan","type":"tool_use","index":0,"partial_json":"{\"steps\": [\"Greet the user and ask about their specific LangChain-related question or issue\"]}"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022","stop_reason":"tool_use","stop_sequence":null},"type":"ai","name":null,"id":"run--27fb1bde-8c18-4056-8549-baa92acf003c","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Greet the user and ask about their specific LangChain-related question or issue"]},"id":"toolu_011AD2TbtpQF3BRbxYAyyoKZ","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":{"input_tokens":586,"output_tokens":53,"total_tokens":639,"input_token_details":{"cache_creation":0,"cache_read":0}}}]

event: debug
data: {"step":1,"timestamp":"2025-09-15T19:26:54.796366+00:00","type":"task_result","payload":{"id":"5e333532-4443-c672-d930-ecf3120c85cd","name":"create_research_plan","error":null,"result":[["steps",["Greet the user and ask about their specific LangChain-related question or issue"]],["documents","delete"],["query","hi"]],"interrupts":[]}}

event: debug
data: {"step":1,"timestamp":"2025-09-15T19:26:54.799033+00:00","type":"checkpoint","payload":{"config":{"configurable":{"checkpoint_ns":"","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_id":"1f09269f-0392-6f0b-8001-16692042b92d"}},"parent_config":{"configurable":{"checkpoint_ns":"","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_id":"1f09269e-f6c8-6e8f-8000-61b81d860490"}},"values":{"messages":[{"content":"hi","additional_kwargs":{},"response_metadata":{},"type":"human","name":null,"id":"7aae7cba-94b6-4218-8747-4f0f66a34000","example":false}],"steps":["Greet the user and ask about their specific LangChain-related question or issue"],"documents":[],"query":"hi"},"metadata":{"source":"loop","step":1,"parents":{}},"next":["conduct_research"],"tasks":[{"id":"112ad8d7-bbc3-68b9-5d81-cead45ae71fb","name":"conduct_research","interrupts":[],"checkpoint":{"thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb"}}],"checkpoint":{"checkpoint_id":"1f09269f-0392-6f0b-8001-16692042b92d","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":""},"parent_checkpoint":{"checkpoint_id":"1f09269e-f6c8-6e8f-8000-61b81d860490","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":""}}}

event: debug
data: {"step":2,"timestamp":"2025-09-15T19:26:54.799056+00:00","type":"task","payload":{"id":"112ad8d7-bbc3-68b9-5d81-cead45ae71fb","name":"conduct_research","input":{"messages":[{"content":"hi","additional_kwargs":{},"response_metadata":{},"type":"human","name":null,"id":"7aae7cba-94b6-4218-8747-4f0f66a34000","example":false}],"router":{"type":"general","logic":""},"steps":["Greet the user and ask about their specific LangChain-related question or issue"],"documents":[],"answer":"","query":"hi"},"triggers":["branch:to:conduct_research"]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":-1,"timestamp":"2025-09-15T19:26:54.807294+00:00","type":"checkpoint","payload":{"config":{"configurable":{"checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a7-684d-bfff-2e6b72ff5736"},"checkpoint_id":"1f09269f-03a7-684d-bfff-2e6b72ff5736"}},"parent_config":null,"values":{"documents":[]},"metadata":{"source":"input","step":-1,"parents":{"":"1f09269f-0392-6f0b-8001-16692042b92d"}},"next":["__start__"],"tasks":[{"id":"7f9d40fe-f70a-c511-3033-b4a6c4d6d736","name":"__start__","interrupts":[],"state":null}],"checkpoint":{"checkpoint_id":"1f09269f-03a7-684d-bfff-2e6b72ff5736","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a7-684d-bfff-2e6b72ff5736"}},"parent_checkpoint":null}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":0,"timestamp":"2025-09-15T19:26:54.807690+00:00","type":"checkpoint","payload":{"config":{"configurable":{"checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a8-69ba-8000-80fdb8a2a254"},"checkpoint_id":"1f09269f-03a8-69ba-8000-80fdb8a2a254"}},"parent_config":{"configurable":{"checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a7-684d-bfff-2e6b72ff5736"},"checkpoint_id":"1f09269f-03a7-684d-bfff-2e6b72ff5736"}},"values":{"question":"Greet the user and ask about their specific LangChain-related question or issue","documents":[]},"metadata":{"source":"loop","step":0,"parents":{"":"1f09269f-0392-6f0b-8001-16692042b92d"}},"next":["generate_queries"],"tasks":[{"id":"1ded568d-0a6a-35e7-cd32-ca7eb1adf769","name":"generate_queries","interrupts":[],"state":null}],"checkpoint":{"checkpoint_id":"1f09269f-03a8-69ba-8000-80fdb8a2a254","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a8-69ba-8000-80fdb8a2a254"}},"parent_checkpoint":{"checkpoint_id":"1f09269f-03a7-684d-bfff-2e6b72ff5736","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a7-684d-bfff-2e6b72ff5736"}}}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":1,"timestamp":"2025-09-15T19:26:54.807703+00:00","type":"task","payload":{"id":"1ded568d-0a6a-35e7-cd32-ca7eb1adf769","name":"generate_queries","input":{"question":"Greet the user and ask about their specific LangChain-related question or issue","queries":[],"documents":[]},"triggers":["branch:to:generate_queries"]}}

event: messages/metadata
data: {"run--49590670-5016-4e9d-83b4-922ca480ada2":{"metadata":{"created_by":"system","from_studio":true,"assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","LANGGRAPH_API_URL":"https://chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","run_attempt":1,"langgraph_version":"0.6.6","langgraph_api_version":"0.4.3","langgraph_plan":"enterprise","langgraph_host":"saas","langgraph_api_url":null,"k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["branch:to:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb|generate_queries:1ded568d-0a6a-35e7-cd32-ca7eb1adf769","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","ls_provider":"anthropic","ls_model_name":"claude-3-5-haiku-20241022","ls_model_type":"chat","ls_temperature":0.0,"ls_max_tokens":1024,"tags":["langsmith:nostream"]}}}

event: messages/partial
data: [{"content":[],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":""}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\""}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\""}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":[""]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain i"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain i"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introductio"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introductio"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introduction\",\"La"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introduction","La"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introduction\",\"LangChain key "}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introduction","LangChain key "]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introduction\",\"LangChain key feature"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introduction","LangChain key feature"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introduction\",\"LangChain key features\",\"LangChai"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introduction","LangChain key features","LangChai"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introduction\",\"LangChain key features\",\"LangChain common use"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introduction","LangChain key features","LangChain common use"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introduction\",\"LangChain key features\",\"LangChain common use cases\"]}"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022"},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introduction","LangChain key features","LangChain common use cases"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":null}]

event: messages/partial
data: [{"content":[{"id":"toolu_01AWPbqzecb1fScHc93VbLxt","input":{},"name":"Response","type":"tool_use","index":0,"partial_json":"{\"queries\": [\"LangChain introduction\",\"LangChain key features\",\"LangChain common use cases\"]}"}],"additional_kwargs":{},"response_metadata":{"model_name":"claude-3-5-haiku-20241022","stop_reason":"tool_use","stop_sequence":null},"type":"ai","name":null,"id":"run--49590670-5016-4e9d-83b4-922ca480ada2","example":false,"tool_calls":[{"name":"Response","args":{"queries":["LangChain introduction","LangChain key features","LangChain common use cases"]},"id":"toolu_01AWPbqzecb1fScHc93VbLxt","type":"tool_call"}],"invalid_tool_calls":[],"usage_metadata":{"input_tokens":582,"output_tokens":56,"total_tokens":638,"input_token_details":{"cache_creation":0,"cache_read":0}}}]

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":1,"timestamp":"2025-09-15T19:26:56.148062+00:00","type":"task_result","payload":{"id":"1ded568d-0a6a-35e7-cd32-ca7eb1adf769","name":"generate_queries","error":null,"result":[["queries",["LangChain introduction","LangChain key features","LangChain common use cases"]]],"interrupts":[]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":1,"timestamp":"2025-09-15T19:26:56.148578+00:00","type":"checkpoint","payload":{"config":{"configurable":{"checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-1071-6d68-8001-a0b98afcc314"},"checkpoint_id":"1f09269f-1071-6d68-8001-a0b98afcc314"}},"parent_config":{"configurable":{"checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a8-69ba-8000-80fdb8a2a254"},"checkpoint_id":"1f09269f-03a8-69ba-8000-80fdb8a2a254"}},"values":{"question":"Greet the user and ask about their specific LangChain-related question or issue","queries":["LangChain introduction","LangChain key features","LangChain common use cases"],"documents":[]},"metadata":{"source":"loop","step":1,"parents":{"":"1f09269f-0392-6f0b-8001-16692042b92d"}},"next":["retrieve_documents","retrieve_documents","retrieve_documents"],"tasks":[{"id":"13244c76-0de7-a8d5-bf3a-a18f6054f1f0","name":"retrieve_documents","interrupts":[],"state":null},{"id":"c5a196ae-0863-dcf7-9b77-d6ad9bc9bc69","name":"retrieve_documents","interrupts":[],"state":null},{"id":"838a2005-2cf5-b6b7-497a-775e0ce4dbdb","name":"retrieve_documents","interrupts":[],"state":null}],"checkpoint":{"checkpoint_id":"1f09269f-1071-6d68-8001-a0b98afcc314","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-1071-6d68-8001-a0b98afcc314"}},"parent_checkpoint":{"checkpoint_id":"1f09269f-03a8-69ba-8000-80fdb8a2a254","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-03a8-69ba-8000-80fdb8a2a254"}}}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":2,"timestamp":"2025-09-15T19:26:56.148595+00:00","type":"task","payload":{"id":"13244c76-0de7-a8d5-bf3a-a18f6054f1f0","name":"retrieve_documents","input":{"query":"LangChain introduction"},"triggers":["__pregel_push"]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":2,"timestamp":"2025-09-15T19:26:56.148602+00:00","type":"task","payload":{"id":"c5a196ae-0863-dcf7-9b77-d6ad9bc9bc69","name":"retrieve_documents","input":{"query":"LangChain key features"},"triggers":["__pregel_push"]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":2,"timestamp":"2025-09-15T19:26:56.148609+00:00","type":"task","payload":{"id":"838a2005-2cf5-b6b7-497a-775e0ce4dbdb","name":"retrieve_documents","input":{"query":"LangChain common use cases"},"triggers":["__pregel_push"]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":2,"timestamp":"2025-09-15T19:26:57.180823+00:00","type":"task_result","payload":{"id":"13244c76-0de7-a8d5-bf3a-a18f6054f1f0","name":"retrieve_documents","error":null,"result":[["documents",[{"id":null,"metadata":{"language":"en","title":"Introduction |  Langchain","changefreq":"weekly","description":"LangChain is a framework for developing applications powered by large language models (LLMs).","priority":"0.5","source":"https://js.langchain.com/docs/introduction","loc":"https://js.langchain.com/docs/introduction","lastmod":null,"uuid":"feabcd8c-edd5-5221-ba28-30ac81c1a391"},"page_content":"Introduction |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.3 |  Langchain","changefreq":"weekly","priority":"0.5","description":"Last updated: 07.08.25","source":"https://js.langchain.com/docs/versions/v0_3/","loc":"https://js.langchain.com/docs/versions/v0_3/","lastmod":null,"uuid":"57aa0c97-cd76-55b6-b034-3466be0e5093"},"page_content":"LangChain v0.3 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.2 |  Langchain","changefreq":"weekly","priority":"0.5","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x, as well as a list of deprecations and breaking changes.","source":"https://js.langchain.com/docs/versions/v0_2/","lastmod":null,"loc":"https://js.langchain.com/docs/versions/v0_2/","uuid":"9541a761-f9ec-5918-8d86-ecf8bf50ac05"},"page_content":"LangChain v0.2 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Documentation Style Guide |  Langchain","changefreq":"weekly","description":"Introduction","priority":"0.5","source":"https://js.langchain.com/docs/contributing/documentation/style_guide","lastmod":null,"loc":"https://js.langchain.com/docs/contributing/documentation/style_guide","uuid":"e88da2f4-10f4-52b4-b0d2-72423f1dc62f"},"page_content":"LangChain Documentation Style Guide |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Expression Language (LCEL) |  Langchain","changefreq":"weekly","priority":"0.5","description":"- Runnable Interface","source":"https://js.langchain.com/docs/concepts/lcel","loc":"https://js.langchain.com/docs/concepts/lcel","lastmod":null,"uuid":"50a26404-c85a-5f56-9589-773b53702159"},"page_content":"LangChain Expression Language (LCEL) |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain releases |  Langchain","changefreq":"weekly","priority":"0.5","description":"The LangChain ecosystem is composed of different component packages (e.g., @langchain/core, langchain, @langchain/community, @langchain/langgraph, partner packages etc.)","source":"https://js.langchain.com/docs/versions/release_policy","loc":"https://js.langchain.com/docs/versions/release_policy","lastmod":null,"uuid":"d7ae11db-bac7-5669-87cc-8629cfb61dd0"},"page_content":"LangChain releases |  Langchain","type":"Document"}]]],"interrupts":[]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":2,"timestamp":"2025-09-15T19:26:57.407075+00:00","type":"task_result","payload":{"id":"c5a196ae-0863-dcf7-9b77-d6ad9bc9bc69","name":"retrieve_documents","error":null,"result":[["documents",[{"id":null,"metadata":{"language":"en","title":"Key-value stores |  Langchain","changefreq":"weekly","priority":"0.5","description":"Key-value stores are used by other LangChain components to store and retrieve data.","source":"https://js.langchain.com/docs/integrations/stores/","loc":"https://js.langchain.com/docs/integrations/stores/","lastmod":null,"uuid":"9f977d9f-3409-5b08-9027-cbe6ddad89cc"},"page_content":"Key-value stores |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.3 |  Langchain","changefreq":"weekly","description":"Last updated: 07.08.25","priority":"0.5","source":"https://js.langchain.com/docs/versions/v0_3/","loc":"https://js.langchain.com/docs/versions/v0_3/","lastmod":null,"uuid":"57aa0c97-cd76-55b6-b034-3466be0e5093"},"page_content":"LangChain v0.3 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.2 |  Langchain","changefreq":"weekly","priority":"0.5","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x, as well as a list of deprecations and breaking changes.","source":"https://js.langchain.com/docs/versions/v0_2/","lastmod":null,"loc":"https://js.langchain.com/docs/versions/v0_2/","uuid":"9541a761-f9ec-5918-8d86-ecf8bf50ac05"},"page_content":"LangChain v0.2 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Key-value stores |  Langchain","changefreq":"weekly","priority":"0.5","description":"Overview","source":"https://js.langchain.com/docs/concepts/key_value_stores","loc":"https://js.langchain.com/docs/concepts/key_value_stores","lastmod":null,"uuid":"187ab437-b454-5862-95a3-8c9e503f0308"},"page_content":"Key-value stores |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Why LangChain? |  Langchain","changefreq":"weekly","description":"The goal of the langchain package and LangChain the company is to make it as easy possible for developers to build applications that reason.","priority":"0.5","source":"https://js.langchain.com/docs/concepts/why_langchain","loc":"https://js.langchain.com/docs/concepts/why_langchain","lastmod":null,"uuid":"071032fb-45e5-56c5-be05-c44a9dcde806"},"page_content":"Why LangChain? |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain releases |  Langchain","changefreq":"weekly","description":"The LangChain ecosystem is composed of different component packages (e.g., @langchain/core, langchain, @langchain/community, @langchain/langgraph, partner packages etc.)","priority":"0.5","source":"https://js.langchain.com/docs/versions/release_policy","lastmod":null,"loc":"https://js.langchain.com/docs/versions/release_policy","uuid":"d7ae11db-bac7-5669-87cc-8629cfb61dd0"},"page_content":"LangChain releases |  Langchain","type":"Document"}]]],"interrupts":[]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":2,"timestamp":"2025-09-15T19:26:57.584811+00:00","type":"task_result","payload":{"id":"838a2005-2cf5-b6b7-497a-775e0ce4dbdb","name":"retrieve_documents","error":null,"result":[["documents",[{"id":null,"metadata":{"language":"en","title":"LangChain v0.3 |  Langchain","changefreq":"weekly","description":"Last updated: 07.08.25","priority":"0.5","source":"https://js.langchain.com/docs/versions/v0_3/","loc":"https://js.langchain.com/docs/versions/v0_3/","lastmod":null,"uuid":"57aa0c97-cd76-55b6-b034-3466be0e5093"},"page_content":"LangChain v0.3 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.2 |  Langchain","changefreq":"weekly","priority":"0.5","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x, as well as a list of deprecations and breaking changes.","source":"https://js.langchain.com/docs/versions/v0_2/","loc":"https://js.langchain.com/docs/versions/v0_2/","lastmod":null,"uuid":"9541a761-f9ec-5918-8d86-ecf8bf50ac05"},"page_content":"LangChain v0.2 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Documentation Style Guide |  Langchain","changefreq":"weekly","description":"Introduction","priority":"0.5","source":"https://js.langchain.com/docs/contributing/documentation/style_guide","loc":"https://js.langchain.com/docs/contributing/documentation/style_guide","lastmod":null,"uuid":"e88da2f4-10f4-52b4-b0d2-72423f1dc62f"},"page_content":"LangChain Documentation Style Guide |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Docusaurus |  LangChain","changefreq":"weekly","description":"Docusaurus is a static-site generator which provides out-of-the-box documentation features.","priority":"0.5","source":"https://python.langchain.com/docs/integrations/document_loaders/docusaurus/","lastmod":null,"loc":"https://python.langchain.com/docs/integrations/document_loaders/docusaurus/","uuid":"8ca8dfbc-51cb-5b5a-9870-a1203e464dfc"},"page_content":"of knowledge or computation. This can include Python REPLs, embeddings, search engines, and more. LangChain provides a large collection of common utils to use in your application.\\\\nChains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\\\nIndexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that.\\\\nAgents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\\\nMemory: Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.\\\\nChat: Chat models are a variation on Language Models that expose a different API - rather than working with raw text, they work with messages. LangChain provides a standard interface for working with them and doing all the same things as above.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nUse Cases#\\\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\\\n\\\\nAgents: Agents are systems that use a language model to interact with other tools. These can be used to do more grounded question/answering, interact with APIs, or even take actions.\\\\nChatbots: Since language models are good at producing text, that makes them ideal for creating chatbots.\\\\nData Augmented Generation: Data Augmented Generation involves specific types of chains that first interact with an external datasource to fetch data to use in the generation step. Examples of this include summarization of long pieces of text and question/answering over specific data sources.\\\\nQuestion Answering: Answering questions over specific documents, only utilizing the information in those documents to construct an answer. A type of Data Augmented Generation.\\\\nSummarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation.\\\\nQuerying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page.\\\\nEvaluation: Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.\\\\nGenerate similar examples: Generating similar examples to a given input. This is a common use case for many applications, and LangChain provides some prompts/chains for assisting in this.\\\\nCompare models: Experimenting with different prompts, models, and chains is a big part of developing the best possible application. The ModelLaboratory makes it easy to do so.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nReference Docs#\\\\nAll of LangChains reference documentation, in one place. Full documentation on all methods, classes, installation methods, and integration setups for LangChain.\\\\n\\\\nReference Documentation\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLangChain Ecosystem#\\\\nGuides for how other companies/products can be used with LangChain\\\\n\\\\nLangChain Ecosystem\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nAdditional Resources#\\\\nAdditional collection of resources we think may be useful as you develop your application!\\\\n\\\\nLangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents.\\\\nGlossary: A glossary of all related terms, papers, methods, etc. Whether implemented in LangChain or not!\\\\nGallery: A collection of our favorite projects that use LangChain. Useful for","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Expression Language (LCEL) |  Langchain","changefreq":"weekly","description":"- Runnable Interface","priority":"0.5","source":"https://js.langchain.com/docs/concepts/lcel","loc":"https://js.langchain.com/docs/concepts/lcel","lastmod":null,"uuid":"50a26404-c85a-5f56-9589-773b53702159"},"page_content":"LangChain Expression Language (LCEL) |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Why LangChain? |  Langchain","changefreq":"weekly","description":"The goal of the langchain package and LangChain the company is to make it as easy possible for developers to build applications that reason.","priority":"0.5","source":"https://js.langchain.com/docs/concepts/why_langchain","lastmod":null,"loc":"https://js.langchain.com/docs/concepts/why_langchain","uuid":"071032fb-45e5-56c5-be05-c44a9dcde806"},"page_content":"Why LangChain? |  Langchain","type":"Document"}]]],"interrupts":[]}}

event: debug|conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb
data: {"step":2,"timestamp":"2025-09-15T19:26:57.585612+00:00","type":"checkpoint","payload":{"config":{"configurable":{"checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-1e26-6892-8002-767754012211"},"checkpoint_id":"1f09269f-1e26-6892-8002-767754012211"}},"parent_config":{"configurable":{"checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-1071-6d68-8001-a0b98afcc314"},"checkpoint_id":"1f09269f-1071-6d68-8001-a0b98afcc314"}},"values":{"question":"Greet the user and ask about their specific LangChain-related question or issue","queries":["LangChain introduction","LangChain key features","LangChain common use cases"],"documents":[{"id":null,"metadata":{"language":"en","title":"Introduction |  Langchain","changefreq":"weekly","description":"LangChain is a framework for developing applications powered by large language models (LLMs).","priority":"0.5","source":"https://js.langchain.com/docs/introduction","loc":"https://js.langchain.com/docs/introduction","lastmod":null,"uuid":"feabcd8c-edd5-5221-ba28-30ac81c1a391"},"page_content":"Introduction |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.3 |  Langchain","changefreq":"weekly","priority":"0.5","description":"Last updated: 07.08.25","source":"https://js.langchain.com/docs/versions/v0_3/","loc":"https://js.langchain.com/docs/versions/v0_3/","lastmod":null,"uuid":"57aa0c97-cd76-55b6-b034-3466be0e5093"},"page_content":"LangChain v0.3 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.2 |  Langchain","changefreq":"weekly","priority":"0.5","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x, as well as a list of deprecations and breaking changes.","source":"https://js.langchain.com/docs/versions/v0_2/","lastmod":null,"loc":"https://js.langchain.com/docs/versions/v0_2/","uuid":"9541a761-f9ec-5918-8d86-ecf8bf50ac05"},"page_content":"LangChain v0.2 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Documentation Style Guide |  Langchain","changefreq":"weekly","description":"Introduction","priority":"0.5","source":"https://js.langchain.com/docs/contributing/documentation/style_guide","lastmod":null,"loc":"https://js.langchain.com/docs/contributing/documentation/style_guide","uuid":"e88da2f4-10f4-52b4-b0d2-72423f1dc62f"},"page_content":"LangChain Documentation Style Guide |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Expression Language (LCEL) |  Langchain","changefreq":"weekly","priority":"0.5","description":"- Runnable Interface","source":"https://js.langchain.com/docs/concepts/lcel","loc":"https://js.langchain.com/docs/concepts/lcel","lastmod":null,"uuid":"50a26404-c85a-5f56-9589-773b53702159"},"page_content":"LangChain Expression Language (LCEL) |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain releases |  Langchain","changefreq":"weekly","priority":"0.5","description":"The LangChain ecosystem is composed of different component packages (e.g., @langchain/core, langchain, @langchain/community, @langchain/langgraph, partner packages etc.)","source":"https://js.langchain.com/docs/versions/release_policy","loc":"https://js.langchain.com/docs/versions/release_policy","lastmod":null,"uuid":"d7ae11db-bac7-5669-87cc-8629cfb61dd0"},"page_content":"LangChain releases |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Key-value stores |  Langchain","changefreq":"weekly","priority":"0.5","description":"Key-value stores are used by other LangChain components to store and retrieve data.","source":"https://js.langchain.com/docs/integrations/stores/","loc":"https://js.langchain.com/docs/integrations/stores/","lastmod":null,"uuid":"9f977d9f-3409-5b08-9027-cbe6ddad89cc"},"page_content":"Key-value stores |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Key-value stores |  Langchain","changefreq":"weekly","priority":"0.5","description":"Overview","source":"https://js.langchain.com/docs/concepts/key_value_stores","loc":"https://js.langchain.com/docs/concepts/key_value_stores","lastmod":null,"uuid":"187ab437-b454-5862-95a3-8c9e503f0308"},"page_content":"Key-value stores |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Why LangChain? |  Langchain","changefreq":"weekly","description":"The goal of the langchain package and LangChain the company is to make it as easy possible for developers to build applications that reason.","priority":"0.5","source":"https://js.langchain.com/docs/concepts/why_langchain","loc":"https://js.langchain.com/docs/concepts/why_langchain","lastmod":null,"uuid":"071032fb-45e5-56c5-be05-c44a9dcde806"},"page_content":"Why LangChain? |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Docusaurus |  LangChain","changefreq":"weekly","description":"Docusaurus is a static-site generator which provides out-of-the-box documentation features.","priority":"0.5","source":"https://python.langchain.com/docs/integrations/document_loaders/docusaurus/","lastmod":null,"loc":"https://python.langchain.com/docs/integrations/document_loaders/docusaurus/","uuid":"8ca8dfbc-51cb-5b5a-9870-a1203e464dfc"},"page_content":"of knowledge or computation. This can include Python REPLs, embeddings, search engines, and more. LangChain provides a large collection of common utils to use in your application.\\\\nChains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\\\nIndexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that.\\\\nAgents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\\\nMemory: Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.\\\\nChat: Chat models are a variation on Language Models that expose a different API - rather than working with raw text, they work with messages. LangChain provides a standard interface for working with them and doing all the same things as above.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nUse Cases#\\\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\\\n\\\\nAgents: Agents are systems that use a language model to interact with other tools. These can be used to do more grounded question/answering, interact with APIs, or even take actions.\\\\nChatbots: Since language models are good at producing text, that makes them ideal for creating chatbots.\\\\nData Augmented Generation: Data Augmented Generation involves specific types of chains that first interact with an external datasource to fetch data to use in the generation step. Examples of this include summarization of long pieces of text and question/answering over specific data sources.\\\\nQuestion Answering: Answering questions over specific documents, only utilizing the information in those documents to construct an answer. A type of Data Augmented Generation.\\\\nSummarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation.\\\\nQuerying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page.\\\\nEvaluation: Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.\\\\nGenerate similar examples: Generating similar examples to a given input. This is a common use case for many applications, and LangChain provides some prompts/chains for assisting in this.\\\\nCompare models: Experimenting with different prompts, models, and chains is a big part of developing the best possible application. The ModelLaboratory makes it easy to do so.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nReference Docs#\\\\nAll of LangChains reference documentation, in one place. Full documentation on all methods, classes, installation methods, and integration setups for LangChain.\\\\n\\\\nReference Documentation\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLangChain Ecosystem#\\\\nGuides for how other companies/products can be used with LangChain\\\\n\\\\nLangChain Ecosystem\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nAdditional Resources#\\\\nAdditional collection of resources we think may be useful as you develop your application!\\\\n\\\\nLangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents.\\\\nGlossary: A glossary of all related terms, papers, methods, etc. Whether implemented in LangChain or not!\\\\nGallery: A collection of our favorite projects that use LangChain. Useful for","type":"Document"}]},"metadata":{"source":"loop","step":2,"parents":{"":"1f09269f-0392-6f0b-8001-16692042b92d"}},"next":[],"tasks":[],"checkpoint":{"checkpoint_id":"1f09269f-1e26-6892-8002-767754012211","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-1e26-6892-8002-767754012211"}},"parent_checkpoint":{"checkpoint_id":"1f09269f-1071-6d68-8001-a0b98afcc314","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","checkpoint_ns":"conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb","checkpoint_map":{"":"1f09269f-0392-6f0b-8001-16692042b92d","conduct_research:112ad8d7-bbc3-68b9-5d81-cead45ae71fb":"1f09269f-1071-6d68-8001-a0b98afcc314"}}}}

event: debug
data: {"step":2,"timestamp":"2025-09-15T19:26:57.602631+00:00","type":"task_result","payload":{"id":"112ad8d7-bbc3-68b9-5d81-cead45ae71fb","name":"conduct_research","error":null,"result":[["documents",[{"id":null,"metadata":{"language":"en","title":"Introduction |  Langchain","changefreq":"weekly","description":"LangChain is a framework for developing applications powered by large language models (LLMs).","priority":"0.5","source":"https://js.langchain.com/docs/introduction","loc":"https://js.langchain.com/docs/introduction","lastmod":null,"uuid":"feabcd8c-edd5-5221-ba28-30ac81c1a391"},"page_content":"Introduction |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.3 |  Langchain","changefreq":"weekly","priority":"0.5","description":"Last updated: 07.08.25","source":"https://js.langchain.com/docs/versions/v0_3/","loc":"https://js.langchain.com/docs/versions/v0_3/","lastmod":null,"uuid":"57aa0c97-cd76-55b6-b034-3466be0e5093"},"page_content":"LangChain v0.3 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.2 |  Langchain","changefreq":"weekly","priority":"0.5","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x, as well as a list of deprecations and breaking changes.","source":"https://js.langchain.com/docs/versions/v0_2/","lastmod":null,"loc":"https://js.langchain.com/docs/versions/v0_2/","uuid":"9541a761-f9ec-5918-8d86-ecf8bf50ac05"},"page_content":"LangChain v0.2 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Documentation Style Guide |  Langchain","changefreq":"weekly","description":"Introduction","priority":"0.5","source":"https://js.langchain.com/docs/contributing/documentation/style_guide","lastmod":null,"loc":"https://js.langchain.com/docs/contributing/documentation/style_guide","uuid":"e88da2f4-10f4-52b4-b0d2-72423f1dc62f"},"page_content":"LangChain Documentation Style Guide |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Expression Language (LCEL) |  Langchain","changefreq":"weekly","priority":"0.5","description":"- Runnable Interface","source":"https://js.langchain.com/docs/concepts/lcel","loc":"https://js.langchain.com/docs/concepts/lcel","lastmod":null,"uuid":"50a26404-c85a-5f56-9589-773b53702159"},"page_content":"LangChain Expression Language (LCEL) |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain releases |  Langchain","changefreq":"weekly","priority":"0.5","description":"The LangChain ecosystem is composed of different component packages (e.g., @langchain/core, langchain, @langchain/community, @langchain/langgraph, partner packages etc.)","source":"https://js.langchain.com/docs/versions/release_policy","loc":"https://js.langchain.com/docs/versions/release_policy","lastmod":null,"uuid":"d7ae11db-bac7-5669-87cc-8629cfb61dd0"},"page_content":"LangChain releases |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Key-value stores |  Langchain","changefreq":"weekly","priority":"0.5","description":"Key-value stores are used by other LangChain components to store and retrieve data.","source":"https://js.langchain.com/docs/integrations/stores/","loc":"https://js.langchain.com/docs/integrations/stores/","lastmod":null,"uuid":"9f977d9f-3409-5b08-9027-cbe6ddad89cc"},"page_content":"Key-value stores |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Key-value stores |  Langchain","changefreq":"weekly","priority":"0.5","description":"Overview","source":"https://js.langchain.com/docs/concepts/key_value_stores","loc":"https://js.langchain.com/docs/concepts/key_value_stores","lastmod":null,"uuid":"187ab437-b454-5862-95a3-8c9e503f0308"},"page_content":"Key-value stores |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Why LangChain? |  Langchain","changefreq":"weekly","description":"The goal of the langchain package and LangChain the company is to make it as easy possible for developers to build applications that reason.","priority":"0.5","source":"https://js.langchain.com/docs/concepts/why_langchain","loc":"https://js.langchain.com/docs/concepts/why_langchain","lastmod":null,"uuid":"071032fb-45e5-56c5-be05-c44a9dcde806"},"page_content":"Why LangChain? |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"Docusaurus |  LangChain","changefreq":"weekly","description":"Docusaurus is a static-site generator which provides out-of-the-box documentation features.","priority":"0.5","source":"https://python.langchain.com/docs/integrations/document_loaders/docusaurus/","lastmod":null,"loc":"https://python.langchain.com/docs/integrations/document_loaders/docusaurus/","uuid":"8ca8dfbc-51cb-5b5a-9870-a1203e464dfc"},"page_content":"of knowledge or computation. This can include Python REPLs, embeddings, search engines, and more. LangChain provides a large collection of common utils to use in your application.\\\\nChains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\\\nIndexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that.\\\\nAgents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\\\nMemory: Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.\\\\nChat: Chat models are a variation on Language Models that expose a different API - rather than working with raw text, they work with messages. LangChain provides a standard interface for working with them and doing all the same things as above.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nUse Cases#\\\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\\\n\\\\nAgents: Agents are systems that use a language model to interact with other tools. These can be used to do more grounded question/answering, interact with APIs, or even take actions.\\\\nChatbots: Since language models are good at producing text, that makes them ideal for creating chatbots.\\\\nData Augmented Generation: Data Augmented Generation involves specific types of chains that first interact with an external datasource to fetch data to use in the generation step. Examples of this include summarization of long pieces of text and question/answering over specific data sources.\\\\nQuestion Answering: Answering questions over specific documents, only utilizing the information in those documents to construct an answer. A type of Data Augmented Generation.\\\\nSummarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation.\\\\nQuerying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page.\\\\nEvaluation: Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.\\\\nGenerate similar examples: Generating similar examples to a given input. This is a common use case for many applications, and LangChain provides some prompts/chains for assisting in this.\\\\nCompare models: Experimenting with different prompts, models, and chains is a big part of developing the best possible application. The ModelLaboratory makes it easy to do so.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nReference Docs#\\\\nAll of LangChains reference documentation, in one place. Full documentation on all methods, classes, installation methods, and integration setups for LangChain.\\\\n\\\\nReference Documentation\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLangChain Ecosystem#\\\\nGuides for how other companies/products can be used with LangChain\\\\n\\\\nLangChain Ecosystem\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nAdditional Resources#\\\\nAdditional collection of resources we think may be useful as you develop your application!\\\\n\\\\nLangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents.\\\\nGlossary: A glossary of all related terms, papers, methods, etc. Whether implemented in LangChain or not!\\\\nGallery: A collection of our favorite projects that use LangChain. Useful for","type":"Document"}]],["steps",[]]],"interrupts":[]}}

event: debug
data: {"step":2,"timestamp":"2025-09-15T19:26:57.605571+00:00","type":"checkpoint","payload":{"config":{"configurable":{"checkpoint_ns":"","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_id":"1f09269f-1e57-6141-8002-9f0597d5daea"}},"parent_config":{"configurable":{"checkpoint_ns":"","k":6,"host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","accept":"*/*","origin":"https://smith.langchain.com","run_id":"01994ed8-29c4-7108-93d4-d649c7a9e370","referer":"https://smith.langchain.com/","user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","graph_id":"chat","priority":"u=1, i","x-scheme":"https","sec-ch-ua":"\"Chromium\";v=\"140\", \"Not=A?Brand\";v=\"24\", \"Google Chrome\";v=\"140\"","thread_id":"23c8ebb7-3500-4f73-9b02-ab2184201bdf","x-real-ip":"10.0.0.161","x-user-id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","user-agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36","query_model":"anthropic/claude-3-5-haiku-20241022","x-tenant-id":"ebbaf2eb-769b-4505-aca2-d11de10372a4","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","content-type":"application/json","x-request-id":"d9ae35cd43d17c9659a1189f43158167","authorization":"Bearer eyJhbGciOiJIUzI1NiIsImtpZCI6IkMyYWJyeEw1YVk2S3V6WHIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3V3c3hydHF1aWZnemFqdGJ3cGlrLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJiOTgyNWI5YS1hYWFkLTQ4OTYtOWI4ZC1jMjg5MDMwZDNiMDMiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzU3OTY0NTQ1LCJpYXQiOjE3NTc5NjQyNDUsImVtYWlsIjoibnVub0BsYW5nY2hhaW4uZGV2IiwicGhvbmUiOiIiLCJhcHBfbWV0YWRhdGEiOnsicHJvdmlkZXIiOiJlbWFpbCIsInByb3ZpZGVycyI6WyJlbWFpbCIsImdvb2dsZSJdfSwidXNlcl9tZXRhZGF0YSI6eyJhdmF0YXJfdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EvQUNnOG9jSlNaNnVkX0szRUdta3l5UWpxd2NxTlA3U0JOOURwaWNKdGlCX0JURHh4UC1haUZ3PXM5Ni1jIiwiY3VzdG9tX2NsYWltcyI6eyJoZCI6ImxhbmdjaGFpbi5kZXYifSwiZW1haWwiOiJudW5vQGxhbmdjaGFpbi5kZXYiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiZnVsbF9uYW1lIjoiTnVubyBDYW1wb3MiLCJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYW1lIjoiTnVubyBDYW1wb3MiLCJwaG9uZV92ZXJpZmllZCI6ZmFsc2UsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NKU1o2dWRfSzNFR21reXlRanF3Y3FOUDdTQk45RHBpY0p0aUJfQlREeHhQLWFpRnc9czk2LWMiLCJwcm92aWRlcl9pZCI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiIsInN1YiI6IjEwODAxMzI4NjAzNDU2MDY4NDcxMiJ9LCJyb2xlIjoiYXV0aGVudGljYXRlZCIsImFhbCI6ImFhbDEiLCJhbXIiOlt7Im1ldGhvZCI6Im9hdXRoIiwidGltZXN0YW1wIjoxNzU3OTYzNzA0fV0sInNlc3Npb25faWQiOiJmNzkyZWViZC1iZmFlLTQ1NjMtOTc0YS0wNWJjOWQ5ZjU3MjgiLCJpc19hbm9ueW1vdXMiOmZhbHNlfQ.AVbI9jO5Arbzzm5JUldGN6MXL6awWefxejLx99d9x9Y","x-auth-scheme":"langsmith","content-length":"5712","response_model":"anthropic/claude-3-5-haiku-20241022","sec-fetch-dest":"empty","sec-fetch-mode":"cors","sec-fetch-site":"cross-site","accept-encoding":"gzip, deflate, br, zstd","accept-language":"en-US,en;q=0.9","embedding_model":"openai/text-embedding-3-small","x-forwarded-for":"10.0.0.161","sec-ch-ua-mobile":"?0","x-forwarded-host":"chat-langchain-v3-823d63bedfd35b5b8540dfc065f1c973.us.langgraph.app","x-forwarded-port":"443","__after_seconds__":0,"x-forwarded-proto":"https","retriever_provider":"weaviate","sec-ch-ua-platform":"\"macOS\"","x-forwarded-scheme":"https","langgraph_auth_user":{"identity":"b9825b9a-aaad-4896-9b8d-c289030d3b03","is_authenticated":true,"display_name":"b9825b9a-aaad-4896-9b8d-c289030d3b03","kind":"StudioUser","permissions":["authenticated"]},"langgraph_request_id":"d9ae35cd43d17c9659a1189f43158167","router_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nA user will come to you with an inquiry. Your first job is to classify what type of inquiry it is. The types of inquiries you should classify it as are:\n\n## `more-info`\nClassify a user inquiry as this if you need more information before you will be able to help them. Examples include:\n- The user complains about an error but doesn't provide the error\n- The user says something isn't working but doesn't explain why/how it's not working\n\n## `langchain`\nClassify a user inquiry as this if it can be answered by looking up information related to LangChain open source package. The LangChain open source package is a python library for working with LLMs. It integrates with various LLMs, databases and APIs.\n\n## `general`\nClassify a user inquiry as this if it is just a general question","general_system_prompt":"You are a LangChain Developer advocate. Your job is to help people using LangChain answer any issues they are running into.\n\nYour boss has determined that the user is asking a general question, not one related to LangChain. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user. Politely decline to answer and tell them you can only answer questions about LangChain-related topics, and that if their question is about LangChain they should clarify how it is.\n\nBe nice to them though - they are still a user!","langgraph_auth_user_id":"b9825b9a-aaad-4896-9b8d-c289030d3b03","response_system_prompt":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${{number}}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity. For any citations, MAKE SURE to hyperlink them like [citation](source url) to make it easy for the user to click into the full docs.\n\n\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS. REMEMBER: you should hyperlink any relevant source urls in the citations so that users can easily click into the full docs.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>","more_info_system_prompt":"You are a LangChain Developer advocate. Your job is help people using LangChain answer any issues they are running into.\n\nYour boss has determined that more information is needed before doing any research on behalf of the user. This was their logic:\n\n<logic>\n{logic}\n</logic>\n\nRespond to the user and try to get any more relevant information. Do not overwhelm them! Be nice, and only ask them a single follow up question.","__request_start_time_ms__":1757964413380,"langgraph_auth_permissions":["authenticated"],"research_plan_system_prompt":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","generate_queries_system_prompt":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","checkpoint_id":"1f09269f-0392-6f0b-8001-16692042b92d"}},"values":{"messages":[{"content":"hi","additional_kwargs":{},"response_metadata":{},"type":"human","name":null,"id":"7aae7cba-94b6-4218-8747-4f0f66a34000","example":false}],"steps":[],"documents":[{"id":null,"metadata":{"language":"en","title":"Introduction |  Langchain","changefreq":"weekly","description":"LangChain is a framework for developing applications powered by large language models (LLMs).","priority":"0.5","source":"https://js.langchain.com/docs/introduction","loc":"https://js.langchain.com/docs/introduction","lastmod":null,"uuid":"feabcd8c-edd5-5221-ba28-30ac81c1a391"},"page_content":"Introduction |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.3 |  Langchain","changefreq":"weekly","priority":"0.5","description":"Last updated: 07.08.25","source":"https://js.langchain.com/docs/versions/v0_3/","loc":"https://js.langchain.com/docs/versions/v0_3/","lastmod":null,"uuid":"57aa0c97-cd76-55b6-b034-3466be0e5093"},"page_content":"LangChain v0.3 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain v0.2 |  Langchain","changefreq":"weekly","priority":"0.5","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x, as well as a list of deprecations and breaking changes.","source":"https://js.langchain.com/docs/versions/v0_2/","lastmod":null,"loc":"https://js.langchain.com/docs/versions/v0_2/","uuid":"9541a761-f9ec-5918-8d86-ecf8bf50ac05"},"page_content":"LangChain v0.2 |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Documentation Style Guide |  Langchain","changefreq":"weekly","description":"Introduction","priority":"0.5","source":"https://js.langchain.com/docs/contributing/documentation/style_guide","lastmod":null,"loc":"https://js.langchain.com/docs/contributing/documentation/style_guide","uuid":"e88da2f4-10f4-52b4-b0d2-72423f1dc62f"},"page_content":"LangChain Documentation Style Guide |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain Expression Language (LCEL) |  Langchain","changefreq":"weekly","priority":"0.5","description":"- Runnable Interface","source":"https://js.langchain.com/docs/concepts/lcel","loc":"https://js.langchain.com/docs/concepts/lcel","lastmod":null,"uuid":"50a26404-c85a-5f56-9589-773b53702159"},"page_content":"LangChain Expression Language (LCEL) |  Langchain","type":"Document"},{"id":null,"metadata":{"language":"en","title":"LangChain releases |  Langchain","changefreq":"weekly","priority":"0.5","description":"The LangChain ecosystem is composed of different component packages (e.g., @langchain/core, langchain, @langchain/community, @langchain/langgraph, partner packages etc.)","source":"https://js.langchain.com/docs/versions/release_policy","loc":"https://js.langchain
```
> [truncated]

---
https://github.com/langchain-ai/langgraph/blob/main/libs/prebuilt/LICENSE
```text
MIT License

Copyright (c) 2024 LangChain, Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```
---
https://github.com/langchain-ai/langgraph/blob/main/libs/prebuilt/Makefile
```text
.PHONY: all format lint test test-fast test_watch integration_tests spell_check spell_fix benchmark profile

# Default target executed when no arguments are given to make.
all: help

######################
# TESTING AND COVERAGE
######################

start-services:
	docker compose -f tests/compose-postgres.yml -f tests/compose-redis.yml up -V --force-recreate --wait --remove-orphans

stop-services:
	docker compose -f tests/compose-postgres.yml -f tests/compose-redis.yml down -v

TEST ?= .

test-fast:
	LANGGRAPH_TEST_FAST=1 uv run pytest $(TEST)

test:
	make start-services && LANGGRAPH_TEST_FAST=0 uv run --active pytest $(TEST); \
	EXIT_CODE=$$?; \
	make stop-services; \
	exit $$EXIT_CODE

test_watch:
	make start-services && LANGGRAPH_TEST_FAST=0 uv run ptw $(TEST); \
	EXIT_CODE=$$?; \
	make stop-services; \
	exit $$EXIT_CODE

######################
# LINTING AND FORMATTING
######################

# Define a variable for Python and notebook files.
PYTHON_FILES=.
MYPY_CACHE=.mypy_cache
lint format: PYTHON_FILES=.
lint_diff format_diff: PYTHON_FILES=$(shell git diff --name-only --relative --diff-filter=d main . | grep -E '\.py$$|\.ipynb$$')
lint_package: PYTHON_FILES=langgraph
lint_tests: PYTHON_FILES=tests
lint_tests: MYPY_CACHE=.mypy_cache_test

lint lint_diff lint_package lint_tests:
	uv run ruff check .
	[ "$(PYTHON_FILES)" = "" ] || uv run ruff format $(PYTHON_FILES) --diff
	[ "$(PYTHON_FILES)" = "" ] || uv run ruff check --select I $(PYTHON_FILES)
	[ "$(PYTHON_FILES)" = "" ] || mkdir -p $(MYPY_CACHE)
	[ "$(PYTHON_FILES)" = "" ] || uv run mypy langgraph --cache-dir $(MYPY_CACHE)

format format_diff:
	uv run ruff format $(PYTHON_FILES)
	uv run ruff check --fix $(PYTHON_FILES)

spell_check:
	uv run codespell --toml pyproject.toml

spell_fix:
	uv run codespell --toml pyproject.toml -w


######################
# HELP
######################

help:
	@echo '===================='
	@echo '-- DOCUMENTATION --'
	
	@echo '-- LINTING --'
	@echo 'format                       - run code formatters'
	@echo 'lint                         - run linters'
	@echo 'spell_check               	- run codespell on the project'
	@echo 'spell_fix               		- run codespell on the project and fix the errors'
	@echo '-- TESTS --'
	@echo 'coverage                     - run unit tests and generate coverage report'
	@echo 'test                         - run unit tests'
	@echo 'test-fast                    - run unit tests with in-memory checkpointer only'
	@echo 'test TEST_FILE=<test_file>   - run all tests in file'
	@echo 'test_watch                   - run unit tests in watch mode'

```
---
https://github.com/langchain-ai/langgraph/blob/main/libs/prebuilt/README.md
```md
# LangGraph Prebuilt

This library defines high-level APIs for creating and executing LangGraph agents and tools.

> [!IMPORTANT]
> This library is meant to be bundled with `langgraph`, don't install it directly

## Agents

`langgraph-prebuilt` provides an [implementation](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) of a tool-calling [ReAct-style](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#react-implementation) agent - `create_react_agent`:

```bash
pip install langchain-anthropic
```

```python
from langchain_anthropic import ChatAnthropic
from langgraph.prebuilt import create_react_agent

# Define the tools for the agent to use
def search(query: str):
    """Call to surf the web."""
    # This is a placeholder, but don't tell the LLM that...
    if "sf" in query.lower() or "san francisco" in query.lower():
        return "It's 60 degrees and foggy."
    return "It's 90 degrees and sunny."

tools = [search]
model = ChatAnthropic(model="claude-3-7-sonnet-latest")

app = create_react_agent(model, tools)
# run the agent
app.invoke(
    {"messages": [{"role": "user", "content": "what is the weather in sf"}]},
)
```

## Tools

### ToolNode

`langgraph-prebuilt` provides an [implementation](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode) of a node that executes tool calls - `ToolNode`:

```python
from langgraph.prebuilt import ToolNode
from langchain_core.messages import AIMessage

def search(query: str):
    """Call to surf the web."""
    # This is a placeholder, but don't tell the LLM that...
    if "sf" in query.lower() or "san francisco" in query.lower():
        return "It's 60 degrees and foggy."
    return "It's 90 degrees and sunny."

tool_node = ToolNode([search])
tool_calls = [{"name": "search", "args": {"query": "what is the weather in sf"}, "id": "1"}]
ai_message = AIMessage(content="", tool_calls=tool_calls)
# execute tool call
tool_node.invoke({"messages": [ai_message]})
```

### ValidationNode

`langgraph-prebuilt` provides an [implementation](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_validator.ValidationNode) of a node that validates tool calls against a pydantic schema - `ValidationNode`:

```python
from pydantic import BaseModel, field_validator
from langgraph.prebuilt import ValidationNode
from langchain_core.messages import AIMessage


class SelectNumber(BaseModel):
    a: int

    @field_validator("a")
    def a_must_be_meaningful(cls, v):
        if v != 37:
            raise ValueError("Only 37 is allowed")
        return v

validation_node = ValidationNode([SelectNumber])
validation_node.invoke({
    "messages": [AIMessage("", tool_calls=[{"name": "SelectNumber", "args": {"a": 42}, "id": "1"}])]
})
```

## Agent Inbox

The library contains schemas for using the [Agent Inbox](https://github.com/langchain-ai/agent-inbox) with LangGraph agents. Learn more about how to use Agent Inbox [here](https://github.com/langchain-ai/agent-inbox#interrupts).

```python
from langgraph.types import interrupt
from langgraph.prebuilt.interrupt import HumanInterrupt, HumanResponse

def my_graph_function():
    # Extract the last tool call from the `messages` field in the state
    tool_call = state["messages"][-1].tool_calls[0]
    # Create an interrupt
    request: HumanInterrupt = {
        "action_request": {
            "action": tool_call['name'],
            "args": tool_call['args']
        },
        "config": {
            "allow_ignore": True,
            "allow_respond": True,
            "allow_edit": False,
            "allow_accept": False
        },
        "description": _generate_email_markdown(state) # Generate a detailed markdown description.
    }
    # Send the interrupt request inside a list, and extract the first response
    response = interrupt([request])[0]
    if response['type'] == "response":
        # Do something with the response
    ...
```
```
---
https://github.com/langchain-ai/langgraph/blob/main/libs/prebuilt/pyproject.toml
```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "langgraph-prebuilt"
version = "1.0.2"
description = "Library with high-level APIs for creating and executing LangGraph agents and tools."
authors = []
requires-python = ">=3.10"
readme = "README.md"
license = "MIT"
license-files = ['LICENSE']
classifiers = [
    'Development Status :: 5 - Production/Stable',
    'Programming Language :: Python',
    'Programming Language :: Python :: Implementation :: CPython',
    'Programming Language :: Python :: Implementation :: PyPy',
    'Programming Language :: Python :: 3',
    'Programming Language :: Python :: 3 :: Only',
    'Programming Language :: Python :: 3.10',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: 3.13',
]
dependencies = [
    "langgraph-checkpoint>=2.1.0,<4.0.0",
    "langchain-core>=1.0.0",
]

[project.urls]
Source = "https://github.com/langchain-ai/langgraph/tree/main/libs/prebuilt"
Twitter = "https://x.com/LangChainAI"
Slack = "https://www.langchain.com/join-community"
Reddit = "https://www.reddit.com/r/LangChain/"

[dependency-groups]
test = [
    "pytest",
    "pytest-asyncio",
    "pytest-mock",
    "pytest-watcher",
    "langchain-core",
    "langgraph",
    "langgraph-checkpoint",
    "langgraph-checkpoint-sqlite",
    "langgraph-checkpoint-postgres",
    "syrupy",
    "psycopg-binary",
]
lint = [
    "ruff",
    "codespell",
    "mypy",
]
dev = [
    {include-group = "test"},
    {include-group = "lint"},
]

[tool.uv]
default-groups = ['dev']

[tool.uv.sources]
langgraph = { path = "../langgraph", editable = true }
langgraph-checkpoint = { path = "../checkpoint", editable = true }
langgraph-checkpoint-sqlite = { path = "../checkpoint-sqlite", editable = true }
langgraph-checkpoint-postgres = { path = "../checkpoint-postgres", editable = true }

[tool.hatch.build.targets.wheel]
include = ["langgraph"]

[tool.pytest.ini_options]
addopts = "--strict-markers --strict-config --durations=5 -vv"
asyncio_mode = "auto"

[tool.ruff]
lint.select = [ "E", "F", "I", "TID251", "UP" ]
lint.ignore = [ "E501" ]
target-version = "py310"

[tool.pytest-watcher]
now = true
delay = 0.1
runner_args = ["--ff", "-v", "--tb", "short"]
patterns = ["*.py"]

[tool.mypy]
# https://mypy.readthedocs.io/en/stable/config_file.html
disallow_untyped_defs = "True"
explicit_package_bases = "True"
warn_no_return = "False"
warn_unused_ignores = "True"
warn_redundant_casts = "True"
allow_redefinition = "True"
disable_error_code = "typeddict-item, return-value"

```
---
https://github.com/langchain-ai/langgraph/blob/main/libs/prebuilt/uv.lock
```lock
version = 1
revision = 3
requires-python = ">=3.10"

[[package]]
name = "aiosqlite"
version = "0.21.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/13/7d/8bca2bf9a247c2c5dfeec1d7a5f40db6518f88d314b8bca9da29670d2671/aiosqlite-0.21.0.tar.gz", hash = "sha256:131bb8056daa3bc875608c631c678cda73922a2d4ba8aec373b19f18c17e7aa3", size = 13454, upload-time = "2025-02-03T07:30:16.235Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f5/10/6c25ed6de94c49f88a91fa5018cb4c0f3625f31d5be9f771ebe5cc7cd506/aiosqlite-0.21.0-py3-none-any.whl", hash = "sha256:2549cf4057f95f53dcba16f2b64e8e2791d7e1adedb13197dd8ed77bb226d7d0", size = 15792, upload-time = "2025-02-03T07:30:13.6Z" },
]

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081, upload-time = "2024-05-20T21:33:25.928Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643, upload-time = "2024-05-20T21:33:24.1Z" },
]

[[package]]
name = "anyio"
version = "4.11.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "exceptiongroup", marker = "python_full_version < '3.11'" },
    { name = "idna" },
    { name = "sniffio" },
    { name = "typing-extensions", marker = "python_full_version < '3.13'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/c6/78/7d432127c41b50bccba979505f272c16cbcadcc33645d5fa3a738110ae75/anyio-4.11.0.tar.gz", hash = "sha256:82a8d0b81e318cc5ce71a5f1f8b5c4e63619620b63141ef8c995fa0db95a57c4", size = 219094, upload-time = "2025-09-23T09:19:12.58Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/15/b3/9b1a8074496371342ec1e796a96f99c82c945a339cd81a8e73de28b4cf9e/anyio-4.11.0-py3-none-any.whl", hash = "sha256:0287e96f4d26d4149305414d4e3bc32f0dcd0862365a4bddea19d7a1ec38c4fc", size = 109097, upload-time = "2025-09-23T09:19:10.601Z" },
]

[[package]]
name = "backports-asyncio-runner"
version = "1.2.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/8e/ff/70dca7d7cb1cbc0edb2c6cc0c38b65cba36cccc491eca64cabd5fe7f8670/backports_asyncio_runner-1.2.0.tar.gz", hash = "sha256:a5aa7b2b7d8f8bfcaa2b57313f70792df84e32a2a746f585213373f900b42162", size = 69893, upload-time = "2025-07-02T02:27:15.685Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a0/59/76ab57e3fe74484f48a53f8e337171b4a2349e506eabe136d7e01d059086/backports_asyncio_runner-1.2.0-py3-none-any.whl", hash = "sha256:0da0a936a8aeb554eccb426dc55af3ba63bcdc69fa1a600b5bb305413a4477b5", size = 12313, upload-time = "2025-07-02T02:27:14.263Z" },
]

[[package]]
name = "certifi"
version = "2025.8.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/dc/67/960ebe6bf230a96cda2e0abcf73af550ec4f090005363542f0765df162e0/certifi-2025.8.3.tar.gz", hash = "sha256:e564105f78ded564e3ae7c923924435e1daa7463faeab5bb932bc53ffae63407", size = 162386, upload-time = "2025-08-03T03:07:47.08Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e5/48/1549795ba7742c948d2ad169c1c8cdbae65bc450d6cd753d124b17c8cd32/certifi-2025.8.3-py3-none-any.whl", hash = "sha256:f6c12493cfb1b06ba2ff328595af9350c65d6644968e5d3a2ffd78699af217a5", size = 161216, upload-time = "2025-08-03T03:07:45.777Z" },
]

[[package]]
name = "charset-normalizer"
version = "3.4.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/83/2d/5fd176ceb9b2fc619e63405525573493ca23441330fcdaee6bef9460e924/charset_normalizer-3.4.3.tar.gz", hash = "sha256:6fce4b8500244f6fcb71465d4a4930d132ba9ab8e71a7859e6a5d59851068d14", size = 122371, upload-time = "2025-08-09T07:57:28.46Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d6/98/f3b8013223728a99b908c9344da3aa04ee6e3fa235f19409033eda92fb78/charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:fb7f67a1bfa6e40b438170ebdc8158b78dc465a5a67b6dde178a46987b244a72", size = 207695, upload-time = "2025-08-09T07:55:36.452Z" },
    { url = "https://files.pythonhosted.org/packages/21/40/5188be1e3118c82dcb7c2a5ba101b783822cfb413a0268ed3be0468532de/charset_normalizer-3.4.3-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:cc9370a2da1ac13f0153780040f465839e6cccb4a1e44810124b4e22483c93fe", size = 147153, upload-time = "2025-08-09T07:55:38.467Z" },
    { url = "https://files.pythonhosted.org/packages/37/60/5d0d74bc1e1380f0b72c327948d9c2aca14b46a9efd87604e724260f384c/charset_normalizer-3.4.3-cp310-cp310-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:07a0eae9e2787b586e129fdcbe1af6997f8d0e5abaa0bc98c0e20e124d67e601", size = 160428, upload-time = "2025-08-09T07:55:40.072Z" },
    { url = "https://files.pythonhosted.org/packages/85/9a/d891f63722d9158688de58d050c59dc3da560ea7f04f4c53e769de5140f5/charset_normalizer-3.4.3-cp310-cp310-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:74d77e25adda8581ffc1c720f1c81ca082921329452eba58b16233ab1842141c", size = 157627, upload-time = "2025-08-09T07:55:41.706Z" },
    { url = "https://files.pythonhosted.org/packages/65/1a/7425c952944a6521a9cfa7e675343f83fd82085b8af2b1373a2409c683dc/charset_normalizer-3.4.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:d0e909868420b7049dafd3a31d45125b31143eec59235311fc4c57ea26a4acd2", size = 152388, upload-time = "2025-08-09T07:55:43.262Z" },
    { url = "https://files.pythonhosted.org/packages/f0/c9/a2c9c2a355a8594ce2446085e2ec97fd44d323c684ff32042e2a6b718e1d/charset_normalizer-3.4.3-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:c6f162aabe9a91a309510d74eeb6507fab5fff92337a15acbe77753d88d9dcf0", size = 150077, upload-time = "2025-08-09T07:55:44.903Z" },
    { url = "https://files.pythonhosted.org/packages/3b/38/20a1f44e4851aa1c9105d6e7110c9d020e093dfa5836d712a5f074a12bf7/charset_normalizer-3.4.3-cp310-cp310-musllinux_1_2_ppc64le.whl", hash = "sha256:4ca4c094de7771a98d7fbd67d9e5dbf1eb73efa4f744a730437d8a3a5cf994f0", size = 161631, upload-time = "2025-08-09T07:55:46.346Z" },
    { url = "https://files.pythonhosted.org/packages/a4/fa/384d2c0f57edad03d7bec3ebefb462090d8905b4ff5a2d2525f3bb711fac/charset_normalizer-3.4.3-cp310-cp310-musllinux_1_2_s390x.whl", hash = "sha256:02425242e96bcf29a49711b0ca9f37e451da7c70562bc10e8ed992a5a7a25cc0", size = 159210, upload-time = "2025-08-09T07:55:47.539Z" },
    { url = "https://files.pythonhosted.org/packages/33/9e/eca49d35867ca2db336b6ca27617deed4653b97ebf45dfc21311ce473c37/charset_normalizer-3.4.3-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:78deba4d8f9590fe4dae384aeff04082510a709957e968753ff3c48399f6f92a", size = 153739, upload-time = "2025-08-09T07:55:48.744Z" },
    { url = "https://files.pythonhosted.org/packages/2a/91/26c3036e62dfe8de8061182d33be5025e2424002125c9500faff74a6735e/charset_normalizer-3.4.3-cp310-cp310-win32.whl", hash = "sha256:d79c198e27580c8e958906f803e63cddb77653731be08851c7df0b1a14a8fc0f", size = 99825, upload-time = "2025-08-09T07:55:50.305Z" },
    { url = "https://files.pythonhosted.org/packages/e2/c6/f05db471f81af1fa01839d44ae2a8bfeec8d2a8b4590f16c4e7393afd323/charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl", hash = "sha256:c6e490913a46fa054e03699c70019ab869e990270597018cef1d8562132c2669", size = 107452, upload-time = "2025-08-09T07:55:51.461Z" },
    { url = "https://files.pythonhosted.org/packages/7f/b5/991245018615474a60965a7c9cd2b4efbaabd16d582a5547c47ee1c7730b/charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:b256ee2e749283ef3ddcff51a675ff43798d92d746d1a6e4631bf8c707d22d0b", size = 204483, upload-time = "2025-08-09T07:55:53.12Z" },
    { url = "https://files.pythonhosted.org/packages/c7/2a/ae245c41c06299ec18262825c1569c5d3298fc920e4ddf56ab011b417efd/charset_normalizer-3.4.3-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:13faeacfe61784e2559e690fc53fa4c5ae97c6fcedb8eb6fb8d0a15b475d2c64", size = 145520, upload-time = "2025-08-09T07:55:54.712Z" },
    { url = "https://files.pythonhosted.org/packages/3a/a4/b3b6c76e7a635748c4421d2b92c7b8f90a432f98bda5082049af37ffc8e3/charset_normalizer-3.4.3-cp311-cp311-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:00237675befef519d9af72169d8604a067d92755e84fe76492fef5441db05b91", size = 158876, upload-time = "2025-08-09T07:55:56.024Z" },
    { url = "https://files.pythonhosted.org/packages/e2/e6/63bb0e10f90a8243c5def74b5b105b3bbbfb3e7bb753915fe333fb0c11ea/charset_normalizer-3.4.3-cp311-cp311-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:585f3b2a80fbd26b048a0be90c5aae8f06605d3c92615911c3a2b03a8a3b796f", size = 156083, upload-time = "2025-08-09T07:55:57.582Z" },
    { url = "https://files.pythonhosted.org/packages/87/df/b7737ff046c974b183ea9aa111b74185ac8c3a326c6262d413bd5a1b8c69/charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:0e78314bdc32fa80696f72fa16dc61168fda4d6a0c014e0380f9d02f0e5d8a07", size = 150295, upload-time = "2025-08-09T07:55:59.147Z" },
    { url = "https://files.pythonhosted.org/packages/61/f1/190d9977e0084d3f1dc169acd060d479bbbc71b90bf3e7bf7b9927dec3eb/charset_normalizer-3.4.3-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:96b2b3d1a83ad55310de8c7b4a2d04d9277d5591f40761274856635acc5fcb30", size = 148379, upload-time = "2025-08-09T07:56:00.364Z" },
    { url = "https://files.pythonhosted.org/packages/4c/92/27dbe365d34c68cfe0ca76f1edd70e8705d82b378cb54ebbaeabc2e3029d/charset_normalizer-3.4.3-cp311-cp311-musllinux_1_2_ppc64le.whl", hash = "sha256:939578d9d8fd4299220161fdd76e86c6a251987476f5243e8864a7844476ba14", size = 160018, upload-time = "2025-08-09T07:56:01.678Z" },
    { url = "https://files.pythonhosted.org/packages/99/04/baae2a1ea1893a01635d475b9261c889a18fd48393634b6270827869fa34/charset_normalizer-3.4.3-cp311-cp311-musllinux_1_2_s390x.whl", hash = "sha256:fd10de089bcdcd1be95a2f73dbe6254798ec1bda9f450d5828c96f93e2536b9c", size = 157430, upload-time = "2025-08-09T07:56:02.87Z" },
    { url = "https://files.pythonhosted.org/packages/2f/36/77da9c6a328c54d17b960c89eccacfab8271fdaaa228305330915b88afa9/charset_normalizer-3.4.3-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:1e8ac75d72fa3775e0b7cb7e4629cec13b7514d928d15ef8ea06bca03ef01cae", size = 151600, upload-time = "2025-08-09T07:56:04.089Z" },
    { url = "https://files.pythonhosted.org/packages/64/d4/9eb4ff2c167edbbf08cdd28e19078bf195762e9bd63371689cab5ecd3d0d/charset_normalizer-3.4.3-cp311-cp311-win32.whl", hash = "sha256:6cf8fd4c04756b6b60146d98cd8a77d0cdae0e1ca20329da2ac85eed779b6849", size = 99616, upload-time = "2025-08-09T07:56:05.658Z" },
    { url = "https://files.pythonhosted.org/packages/f4/9c/996a4a028222e7761a96634d1820de8a744ff4327a00ada9c8942033089b/charset_normalizer-3.4.3-cp311-cp311-win_amd64.whl", hash = "sha256:31a9a6f775f9bcd865d88ee350f0ffb0e25936a7f930ca98995c05abf1faf21c", size = 107108, upload-time = "2025-08-09T07:56:07.176Z" },
    { url = "https://files.pythonhosted.org/packages/e9/5e/14c94999e418d9b87682734589404a25854d5f5d0408df68bc15b6ff54bb/charset_normalizer-3.4.3-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:e28e334d3ff134e88989d90ba04b47d84382a828c061d0d1027b1b12a62b39b1", size = 205655, upload-time = "2025-08-09T07:56:08.475Z" },
    { url = "https://files.pythonhosted.org/packages/7d/a8/c6ec5d389672521f644505a257f50544c074cf5fc292d5390331cd6fc9c3/charset_normalizer-3.4.3-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:0cacf8f7297b0c4fcb74227692ca46b4a5852f8f4f24b3c766dd94a1075c4884", size = 146223, upload-time = "2025-08-09T07:56:09.708Z" },
    { url = "https://files.pythonhosted.org/packages/fc/eb/a2ffb08547f4e1e5415fb69eb7db25932c52a52bed371429648db4d84fb1/charset_normalizer-3.4.3-cp312-cp312-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:c6fd51128a41297f5409deab284fecbe5305ebd7e5a1f959bee1c054622b7018", size = 159366, upload-time = "2025-08-09T07:56:11.326Z" },
    { url = "https://files.pythonhosted.org/packages/82/10/0fd19f20c624b278dddaf83b8464dcddc2456cb4b02bb902a6da126b87a1/charset_normalizer-3.4.3-cp312-cp312-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:3cfb2aad70f2c6debfbcb717f23b7eb55febc0bb23dcffc0f076009da10c6392", size = 157104, upload-time = "2025-08-09T07:56:13.014Z" },
    { url = "https://files.pythonhosted.org/packages/16/ab/0233c3231af734f5dfcf0844aa9582d5a1466c985bbed6cedab85af9bfe3/charset_normalizer-3.4.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:1606f4a55c0fd363d754049cdf400175ee96c992b1f8018b993941f221221c5f", size = 151830, upload-time = "2025-08-09T07:56:14.428Z" },
    { url = "https://files.pythonhosted.org/packages/ae/02/e29e22b4e02839a0e4a06557b1999d0a47db3567e82989b5bb21f3fbbd9f/charset_normalizer-3.4.3-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:027b776c26d38b7f15b26a5da1044f376455fb3766df8fc38563b4efbc515154", size = 148854, upload-time = "2025-08-09T07:56:16.051Z" },
    { url = "https://files.pythonhosted.org/packages/05/6b/e2539a0a4be302b481e8cafb5af8792da8093b486885a1ae4d15d452bcec/charset_normalizer-3.4.3-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:42e5088973e56e31e4fa58eb6bd709e42fc03799c11c42929592889a2e54c491", size = 160670, upload-time = "2025-08-09T07:56:17.314Z" },
    { url = "https://files.pythonhosted.org/packages/31/e7/883ee5676a2ef217a40ce0bffcc3d0dfbf9e64cbcfbdf822c52981c3304b/charset_normalizer-3.4.3-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:cc34f233c9e71701040d772aa7490318673aa7164a0efe3172b2981218c26d93", size = 158501, upload-time = "2025-08-09T07:56:18.641Z" },
    { url = "https://files.pythonhosted.org/packages/c1/35/6525b21aa0db614cf8b5792d232021dca3df7f90a1944db934efa5d20bb1/charset_normalizer-3.4.3-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:320e8e66157cc4e247d9ddca8e21f427efc7a04bbd0ac8a9faf56583fa543f9f", size = 153173, upload-time = "2025-08-09T07:56:20.289Z" },
    { url = "https://files.pythonhosted.org/packages/50/ee/f4704bad8201de513fdc8aac1cabc87e38c5818c93857140e06e772b5892/charset_normalizer-3.4.3-cp312-cp312-win32.whl", hash = "sha256:fb6fecfd65564f208cbf0fba07f107fb661bcd1a7c389edbced3f7a493f70e37", size = 99822, upload-time = "2025-08-09T07:56:21.551Z" },
    { url = "https://files.pythonhosted.org/packages/39/f5/3b3836ca6064d0992c58c7561c6b6eee1b3892e9665d650c803bd5614522/charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl", hash = "sha256:86df271bf921c2ee3818f0522e9a5b8092ca2ad8b065ece5d7d9d0e9f4849bcc", size = 107543, upload-time = "2025-08-09T07:56:23.115Z" },
    { url = "https://files.pythonhosted.org/packages/65/ca/2135ac97709b400c7654b4b764daf5c5567c2da45a30cdd20f9eefe2d658/charset_normalizer-3.4.3-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:14c2a87c65b351109f6abfc424cab3927b3bdece6f706e4d12faaf3d52ee5efe", size = 205326, upload-time = "2025-08-09T07:56:24.721Z" },
    { url = "https://files.pythonhosted.org/packages/71/11/98a04c3c97dd34e49c7d247083af03645ca3730809a5509443f3c37f7c99/charset_normalizer-3.4.3-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:41d1fc408ff5fdfb910200ec0e74abc40387bccb3252f3f27c0676731df2b2c8", size = 146008, upload-time = "2025-08-09T07:56:26.004Z" },
    { url = "https://files.pythonhosted.org/packages/60/f5/4659a4cb3c4ec146bec80c32d8bb16033752574c20b1252ee842a95d1a1e/charset_normalizer-3.4.3-cp313-cp313-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:1bb60174149316da1c35fa5233681f7c0f9f514509b8e399ab70fea5f17e45c9", size = 159196, upload-time = "2025-08-09T07:56:27.25Z" },
    { url = "https://files.pythonhosted.org/packages/86/9e/f552f7a00611f168b9a5865a1414179b2c6de8235a4fa40189f6f79a1753/charset_normalizer-3.4.3-cp313-cp313-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:30d006f98569de3459c2fc1f2acde170b7b2bd265dc1943e87e1a4efe1b67c31", size = 156819, upload-time = "2025-08-09T07:56:28.515Z" },
    { url = "https://files.pythonhosted.org/packages/7e/95/42aa2156235cbc8fa61208aded06ef46111c4d3f0de233107b3f38631803/charset_normalizer-3.4.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:416175faf02e4b0810f1f38bcb54682878a4af94059a1cd63b8747244420801f", size = 151350, upload-time = "2025-08-09T07:56:29.716Z" },
    { url = "https://files.pythonhosted.org/packages/c2/a9/3865b02c56f300a6f94fc631ef54f0a8a29da74fb45a773dfd3dcd380af7/charset_normalizer-3.4.3-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:6aab0f181c486f973bc7262a97f5aca3ee7e1437011ef0c2ec04b5a11d16c927", size = 148644, upload-time = "2025-08-09T07:56:30.984Z" },
    { url = "https://files.pythonhosted.org/packages/77/d9/cbcf1a2a5c7d7856f11e7ac2d782aec12bdfea60d104e60e0aa1c97849dc/charset_normalizer-3.4.3-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:fdabf8315679312cfa71302f9bd509ded4f2f263fb5b765cf1433b39106c3cc9", size = 160468, upload-time = "2025-08-09T07:56:32.252Z" },
    { url = "https://files.pythonhosted.org/packages/f6/42/6f45efee8697b89fda4d50580f292b8f7f9306cb2971d4b53f8914e4d890/charset_normalizer-3.4.3-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:bd28b817ea8c70215401f657edef3a8aa83c29d447fb0b622c35403780ba11d5", size = 158187, upload-time = "2025-08-09T07:56:33.481Z" },
    { url = "https://files.pythonhosted.org/packages/70/99/f1c3bdcfaa9c45b3ce96f70b14f070411366fa19549c1d4832c935d8e2c3/charset_normalizer-3.4.3-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:18343b2d246dc6761a249ba1fb13f9ee9a2bcd95decc767319506056ea4ad4dc", size = 152699, upload-time = "2025-08-09T07:56:34.739Z" },
    { url = "https://files.pythonhosted.org/packages/a3/ad/b0081f2f99a4b194bcbb1934ef3b12aa4d9702ced80a37026b7607c72e58/charset_normalizer-3.4.3-cp313-cp313-win32.whl", hash = "sha256:6fb70de56f1859a3f71261cbe41005f56a7842cc348d3aeb26237560bfa5e0ce", size = 99580, upload-time = "2025-08-09T07:56:35.981Z" },
    { url = "https://files.pythonhosted.org/packages/9a/8f/ae790790c7b64f925e5c953b924aaa42a243fb778fed9e41f147b2a5715a/charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl", hash = "sha256:cf1ebb7d78e1ad8ec2a8c4732c7be2e736f6e5123a4146c5b89c9d1f585f8cef", size = 107366, upload-time = "2025-08-09T07:56:37.339Z" },
    { url = "https://files.pythonhosted.org/packages/8e/91/b5a06ad970ddc7a0e513112d40113e834638f4ca1120eb727a249fb2715e/charset_normalizer-3.4.3-cp314-cp314-macosx_10_13_universal2.whl", hash = "sha256:3cd35b7e8aedeb9e34c41385fda4f73ba609e561faedfae0a9e75e44ac558a15", size = 204342, upload-time = "2025-08-09T07:56:38.687Z" },
    { url = "https://files.pythonhosted.org/packages/ce/ec/1edc30a377f0a02689342f214455c3f6c2fbedd896a1d2f856c002fc3062/charset_normalizer-3.4.3-cp314-cp314-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:b89bc04de1d83006373429975f8ef9e7932534b8cc9ca582e4db7d20d91816db", size = 145995, upload-time = "2025-08-09T07:56:40.048Z" },
    { url = "https://files.pythonhosted.org/packages/17/e5/5e67ab85e6d22b04641acb5399c8684f4d37caf7558a53859f0283a650e9/charset_normalizer-3.4.3-cp314-cp314-manylinux2014_ppc64le.manylinux_2_17_ppc64le.manylinux_2_28_ppc64le.whl", hash = "sha256:2001a39612b241dae17b4687898843f254f8748b796a2e16f1051a17078d991d", size = 158640, upload-time = "2025-08-09T07:56:41.311Z" },
    { url = "https://files.pythonhosted.org/packages/f1/e5/38421987f6c697ee3722981289d554957c4be652f963d71c5e46a262e135/charset_normalizer-3.4.3-cp314-cp314-manylinux2014_s390x.manylinux_2_17_s390x.manylinux_2_28_s390x.whl", hash = "sha256:8dcfc373f888e4fb39a7bc57e93e3b845e7f462dacc008d9749568b1c4ece096", size = 156636, upload-time = "2025-08-09T07:56:43.195Z" },
    { url = "https://files.pythonhosted.org/packages/a0/e4/5a075de8daa3ec0745a9a3b54467e0c2967daaaf2cec04c845f73493e9a1/charset_normalizer-3.4.3-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:18b97b8404387b96cdbd30ad660f6407799126d26a39ca65729162fd810a99aa", size = 150939, upload-time = "2025-08-09T07:56:44.819Z" },
    { url = "https://files.pythonhosted.org/packages/02/f7/3611b32318b30974131db62b4043f335861d4d9b49adc6d57c1149cc49d4/charset_normalizer-3.4.3-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:ccf600859c183d70eb47e05a44cd80a4ce77394d1ac0f79dbd2dd90a69a3a049", size = 148580, upload-time = "2025-08-09T07:56:46.684Z" },
    { url = "https://files.pythonhosted.org/packages/7e/61/19b36f4bd67f2793ab6a99b979b4e4f3d8fc754cbdffb805335df4337126/charset_normalizer-3.4.3-cp314-cp314-musllinux_1_2_ppc64le.whl", hash = "sha256:53cd68b185d98dde4ad8990e56a58dea83a4162161b1ea9272e5c9182ce415e0", size = 159870, upload-time = "2025-08-09T07:56:47.941Z" },
    { url = "https://files.pythonhosted.org/packages/06/57/84722eefdd338c04cf3030ada66889298eaedf3e7a30a624201e0cbe424a/charset_normalizer-3.4.3-cp314-cp314-musllinux_1_2_s390x.whl", hash = "sha256:30a96e1e1f865f78b030d65241c1ee850cdf422d869e9028e2fc1d5e4db73b92", size = 157797, upload-time = "2025-08-09T07:56:49.756Z" },
    { url = "https://files.pythonhosted.org/packages/72/2a/aff5dd112b2f14bcc3462c312dce5445806bfc8ab3a7328555da95330e4b/charset_normalizer-3.4.3-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:d716a916938e03231e86e43782ca7878fb602a125a91e7acb8b5112e2e96ac16", size = 152224, upload-time = "2025-08-09T07:56:51.369Z" },
    { url = "https://files.pythonhosted.org/packages/b7/8c/9839225320046ed279c6e839d51f028342eb77c91c89b8ef2549f951f3ec/charset_normalizer-3.4.3-cp314-cp314-win32.whl", hash = "sha256:c6dbd0ccdda3a2ba7c2ecd9d77b37f3b5831687d8dc1b6ca5f56a4880cc7b7ce", size = 100086, upload-time = "2025-08-09T07:56:52.722Z" },
    { url = "https://files.pythonhosted.org/packages/ee/7a/36fbcf646e41f710ce0a563c1c9a343c6edf9be80786edeb15b6f62e17db/charset_normalizer-3.4.3-cp314-cp314-win_amd64.whl", hash = "sha256:73dc19b562516fc9bcf6e5d6e596df0b4eb98d87e4f79f3ae71840e6ed21361c", size = 107400, upload-time = "2025-08-09T07:56:55.172Z" },
    { url = "https://files.pythonhosted.org/packages/8a/1f/f041989e93b001bc4e44bb1669ccdcf54d3f00e628229a85b08d330615c5/charset_normalizer-3.4.3-py3-none-any.whl", hash = "sha256:ce571ab16d890d23b5c278547ba694193a45011ff86a9162a71307ed9f86759a", size = 53175, upload-time = "2025-08-09T07:57:26.864Z" },
]

[[package]]
name = "codespell"
version = "2.4.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/15/e0/709453393c0ea77d007d907dd436b3ee262e28b30995ea1aa36c6ffbccaf/codespell-2.4.1.tar.gz", hash = "sha256:299fcdcb09d23e81e35a671bbe746d5ad7e8385972e65dbb833a2eaac33c01e5", size = 344740, upload-time = "2025-01-28T18:52:39.411Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/20/01/b394922252051e97aab231d416c86da3d8a6d781eeadcdca1082867de64e/codespell-2.4.1-py3-none-any.whl", hash = "sha256:3dadafa67df7e4a3dbf51e0d7315061b80d265f9552ebd699b3dd6834b47e425", size = 344501, upload-time = "2025-01-28T18:52:37.057Z" },
]

[[package]]
name = "colorama"
version = "0.4.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d8/53/6f443c9a4a8358a93a6792e2acffb9d9d5cb0a5cfd8802644b7b1c9a02e4/colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44", size = 27697, upload-time = "2022-10-25T02:36:22.414Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6", size = 25335, upload-time = "2022-10-25T02:36:20.889Z" },
]

[[package]]
name = "exceptiongroup"
version = "1.3.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions", marker = "python_full_version < '3.13'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/0b/9f/a65090624ecf468cdca03533906e7c69ed7588582240cfe7cc9e770b50eb/exceptiongroup-1.3.0.tar.gz", hash = "sha256:b241f5885f560bc56a59ee63ca4c6a8bfa46ae4ad651af316d4e81817bb9fd88", size = 29749, upload-time = "2025-05-10T17:42:51.123Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/36/f4/c6e662dade71f56cd2f3735141b265c3c79293c109549c1e6933b0651ffc/exceptiongroup-1.3.0-py3-none-any.whl", hash = "sha256:4d111e6e0c13d0644cad6ddaa7ed0261a0b36971f6d23e7ec9b4b9097da78a10", size = 16674, upload-time = "2025-05-10T17:42:49.33Z" },
]

[[package]]
name = "h11"
version = "0.16.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/01/ee/02a2c011bdab74c6fb3c75474d40b3052059d95df7e73351460c8588d963/h11-0.16.0.tar.gz", hash = "sha256:4e35b956cf45792e4caa5885e69fba00bdbc6ffafbfa020300e549b208ee5ff1", size = 101250, upload-time = "2025-04-24T03:35:25.427Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/04/4b/29cac41a4d98d144bf5f6d33995617b185d14b22401f75ca86f384e87ff1/h11-0.16.0-py3-none-any.whl", hash = "sha256:63cf8bbe7522de3bf65932fda1d9c2772064ffb3dae62d55932da54b31cb6c86", size = 37515, upload-time = "2025-04-24T03:35:24.344Z" },
]

[[package]]
name = "httpcore"
version = "1.0.9"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/06/94/82699a10bca87a5556c9c59b5963f2d039dbd239f25bc2a63907a05a14cb/httpcore-1.0.9.tar.gz", hash = "sha256:6e34463af53fd2ab5d807f399a9b45ea31c3dfa2276f15a2c3f00afff6e176e8", size = 85484, upload-time = "2025-04-24T22:06:22.219Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/f5/f66802a942d491edb555dd61e3a9961140fd64c90bce1eafd741609d334d/httpcore-1.0.9-py3-none-any.whl", hash = "sha256:2d400746a40668fc9dec9810239072b40b4484b640a8c38fd654a024c7a1bf55", size = 78784, upload-time = "2025-04-24T22:06:20.566Z" },
]

[[package]]
name = "httpx"
version = "0.28.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "certifi" },
    { name = "httpcore" },
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/df/48c586a5fe32a0f01324ee087459e112ebb7224f646c0b5023f5e79e9956/httpx-0.28.1.tar.gz", hash = "sha256:75e98c5f16b0f35b567856f597f06ff2270a374470a5c2392242528e3e3e42fc", size = 141406, upload-time = "2024-12-06T15:37:23.222Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl", hash = "sha256:d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad", size = 73517, upload-time = "2024-12-06T15:37:21.509Z" },
]

[[package]]
name = "idna"
version = "3.10"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/70/7703c29685631f5a7590aa73f1f1d3fa9a380e654b86af429e0934a32f7d/idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9", size = 190490, upload-time = "2024-09-15T18:07:39.745Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3", size = 70442, upload-time = "2024-09-15T18:07:37.964Z" },
]

[[package]]
name = "iniconfig"
version = "2.1.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f2/97/ebf4da567aa6827c909642694d71c9fcf53e5b504f2d96afea02718862f3/iniconfig-2.1.0.tar.gz", hash = "sha256:3abbd2e30b36733fee78f9c7f7308f2d0050e88f0087fd25c2645f63c773e1c7", size = 4793, upload-time = "2025-03-19T20:09:59.721Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2c/e1/e6716421ea10d38022b952c159d5161ca1193197fb744506875fbb87ea7b/iniconfig-2.1.0-py3-none-any.whl", hash = "sha256:9deba5723312380e77435581c6bf4935c94cbfab9b1ed33ef8d238ea168eb760", size = 6050, upload-time = "2025-03-19T20:10:01.071Z" },
]

[[package]]
name = "jsonpatch"
version = "1.33"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "jsonpointer" },
]
sdist = { url = "https://files.pythonhosted.org/packages/42/78/18813351fe5d63acad16aec57f94ec2b70a09e53ca98145589e185423873/jsonpatch-1.33.tar.gz", hash = "sha256:9fcd4009c41e6d12348b4a0ff2563ba56a2923a7dfee731d004e212e1ee5030c", size = 21699, upload-time = "2023-06-26T12:07:29.144Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl", hash = "sha256:0ae28c0cd062bbd8b8ecc26d7d164fbbea9652a1a3693f3b956c1eae5145dade", size = 12898, upload-time = "2023-06-16T21:01:28.466Z" },
]

[[package]]
name = "jsonpointer"
version = "3.0.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/6a/0a/eebeb1fa92507ea94016a2a790b93c2ae41a7e18778f85471dc54475ed25/jsonpointer-3.0.0.tar.gz", hash = "sha256:2b2d729f2091522d61c3b31f82e11870f60b68f43fbc705cb76bf4b832af59ef", size = 9114, upload-time = "2024-06-10T19:24:42.462Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl", hash = "sha256:13e088adc14fca8b6aa8177c044e12701e6ad4b28ff10e65f2267a90109c9942", size = 7595, upload-time = "2024-06-10T19:24:40.698Z" },
]

[[package]]
name = "langchain-core"
version = "1.0.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "jsonpatch" },
    { name = "langsmith" },
    { name = "packaging" },
    { name = "pydantic" },
    { name = "pyyaml" },
    { name = "tenacity" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ad/d0/9db6d375ecf8bd498fcc87016e43c3d930ddbfbacf9a1e99018ada4e824f/langchain_core-1.0.0.tar.gz", hash = "sha256:8e81c94a22fa3a362a0f101bbd1271bf3725e50cf1e31c84e8f4a1c731279785", size = 764484, upload-time = "2025-10-17T13:48:24.408Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/68/6a/8dd566cb7379d6e3a921f94713babba2f71cbed65c73c784c649c1fd7d4e/langchain_core-1.0.0-py3-none-any.whl", hash = "sha256:a94561bf75dd097c7d6e3864950f28dadc963f0bd810114de4095f41f634059b", size = 467157, upload-time = "2025-10-17T13:48:23.138Z" },
]

[[package]]
name = "langgraph"
version = "1.0.3"
source = { editable = "../langgraph" }
dependencies = [
    { name = "langchain-core" },
    { name = "langgraph-checkpoint" },
    { name = "langgraph-prebuilt" },
    { name = "langgraph-sdk" },
    { name = "pydantic" },
    { name = "xxhash" },
]

[package.metadata]
requires-dist = [
    { name = "langchain-core", specifier = ">=0.1" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "langgraph-prebuilt", editable = "." },
    { name = "langgraph-sdk", editable = "../sdk-py" },
    { name = "pydantic", specifier = ">=2.7.4" },
    { name = "xxhash", specifier = ">=3.5.0" },
]

[package.metadata.requires-dev]
dev = [
    { name = "httpx" },
    { name = "jupyter" },
    { name = "langchain-core", specifier = ">=1.0.0" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "langgraph-checkpoint-postgres", editable = "../checkpoint-postgres" },
    { name = "langgraph-checkpoint-sqlite", editable = "../checkpoint-sqlite" },
    { name = "langgraph-cli", marker = "python_full_version < '3.14'", editable = "../cli" },
    { name = "langgraph-cli", extras = ["inmem"], marker = "python_full_version < '3.14'", editable = "../cli" },
    { name = "langgraph-prebuilt", editable = "." },
    { name = "langgraph-sdk", editable = "../sdk-py" },
    { name = "mypy" },
    { name = "psycopg", extras = ["binary"] },
    { name = "py-spy" },
    { name = "pycryptodome" },
    { name = "pyperf" },
    { name = "pytest" },
    { name = "pytest-cov" },
    { name = "pytest-dotenv" },
    { name = "pytest-mock" },
    { name = "pytest-repeat" },
    { name = "pytest-watcher" },
    { name = "pytest-xdist", extras = ["psutil"] },
    { name = "redis" },
    { name = "ruff" },
    { name = "syrupy" },
    { name = "types-requests" },
    { name = "uvloop", specifier = "==0.21.0b1" },
]
lint = [
    { name = "mypy" },
    { name = "ruff" },
    { name = "types-requests" },
]
test = [
    { name = "httpx" },
    { name = "langchain-core", specifier = ">=1.0.0" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "langgraph-checkpoint-postgres", editable = "../checkpoint-postgres" },
    { name = "langgraph-checkpoint-sqlite", editable = "../checkpoint-sqlite" },
    { name = "langgraph-cli", marker = "python_full_version < '3.14'", editable = "../cli" },
    { name = "langgraph-cli", extras = ["inmem"], marker = "python_full_version < '3.14'", editable = "../cli" },
    { name = "langgraph-prebuilt", editable = "." },
    { name = "langgraph-sdk", editable = "../sdk-py" },
    { name = "psycopg", extras = ["binary"] },
    { name = "py-spy" },
    { name = "pycryptodome" },
    { name = "pyperf" },
    { name = "pytest" },
    { name = "pytest-cov" },
    { name = "pytest-dotenv" },
    { name = "pytest-mock" },
    { name = "pytest-repeat" },
    { name = "pytest-watcher" },
    { name = "pytest-xdist", extras = ["psutil"] },
    { name = "redis" },
    { name = "syrupy" },
    { name = "uvloop", specifier = "==0.21.0b1" },
]

[[package]]
name = "langgraph-checkpoint"
version = "3.0.1"
source = { editable = "../checkpoint" }
dependencies = [
    { name = "langchain-core" },
    { name = "ormsgpack" },
]

[package.metadata]
requires-dist = [
    { name = "langchain-core", specifier = ">=0.2.38" },
    { name = "ormsgpack", specifier = ">=1.12.0" },
]

[package.metadata.requires-dev]
dev = [
    { name = "codespell" },
    { name = "dataclasses-json" },
    { name = "mypy" },
    { name = "numpy" },
    { name = "pandas" },
    { name = "pandas-stubs", specifier = ">=2.2.2.240807" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
    { name = "redis" },
    { name = "ruff" },
]
lint = [
    { name = "codespell" },
    { name = "mypy" },
    { name = "ruff" },
]
test = [
    { name = "dataclasses-json" },
    { name = "numpy" },
    { name = "pandas" },
    { name = "pandas-stubs", specifier = ">=2.2.2.240807" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
    { name = "redis" },
]

[[package]]
name = "langgraph-checkpoint-postgres"
version = "3.0.1"
source = { editable = "../checkpoint-postgres" }
dependencies = [
    { name = "langgraph-checkpoint" },
    { name = "orjson" },
    { name = "psycopg" },
    { name = "psycopg-pool" },
]

[package.metadata]
requires-dist = [
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "orjson", specifier = ">=3.10.1" },
    { name = "psycopg", specifier = ">=3.2.0" },
    { name = "psycopg-pool", specifier = ">=3.2.0" },
]

[package.metadata.requires-dev]
dev = [
    { name = "anyio" },
    { name = "codespell" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "mypy" },
    { name = "psycopg", extras = ["binary"] },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
    { name = "ruff" },
]
lint = [
    { name = "codespell" },
    { name = "mypy" },
    { name = "ruff" },
]
test = [
    { name = "anyio" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "psycopg", extras = ["binary"] },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
]

[[package]]
name = "langgraph-checkpoint-sqlite"
version = "3.0.0"
source = { editable = "../checkpoint-sqlite" }
dependencies = [
    { name = "aiosqlite" },
    { name = "langgraph-checkpoint" },
    { name = "sqlite-vec" },
]

[package.metadata]
requires-dist = [
    { name = "aiosqlite", specifier = ">=0.20" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "sqlite-vec", specifier = ">=0.1.6" },
]

[package.metadata.requires-dev]
dev = [
    { name = "codespell" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "mypy" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-retry", specifier = ">=1.7.0" },
    { name = "pytest-watcher" },
    { name = "ruff" },
]
lint = [
    { name = "codespell" },
    { name = "mypy" },
    { name = "ruff" },
]
test = [
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-retry", specifier = ">=1.7.0" },
    { name = "pytest-watcher" },
]

[[package]]
name = "langgraph-prebuilt"
version = "1.0.2"
source = { editable = "." }
dependencies = [
    { name = "langchain-core" },
    { name = "langgraph-checkpoint" },
]

[package.dev-dependencies]
dev = [
    { name = "codespell" },
    { name = "langchain-core" },
    { name = "langgraph" },
    { name = "langgraph-checkpoint" },
    { name = "langgraph-checkpoint-postgres" },
    { name = "langgraph-checkpoint-sqlite" },
    { name = "mypy" },
    { name = "psycopg-binary" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
    { name = "ruff" },
    { name = "syrupy" },
]
lint = [
    { name = "codespell" },
    { name = "mypy" },
    { name = "ruff" },
]
test = [
    { name = "langchain-core" },
    { name = "langgraph" },
    { name = "langgraph-checkpoint" },
    { name = "langgraph-checkpoint-postgres" },
    { name = "langgraph-checkpoint-sqlite" },
    { name = "psycopg-binary" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
    { name = "syrupy" },
]

[package.metadata]
requires-dist = [
    { name = "langchain-core", specifier = ">=1.0.0" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
]

[package.metadata.requires-dev]
dev = [
    { name = "codespell" },
    { name = "langchain-core" },
    { name = "langgraph", editable = "../langgraph" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "langgraph-checkpoint-postgres", editable = "../checkpoint-postgres" },
    { name = "langgraph-checkpoint-sqlite", editable = "../checkpoint-sqlite" },
    { name = "mypy" },
    { name = "psycopg-binary" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
    { name = "ruff" },
    { name = "syrupy" },
]
lint = [
    { name = "codespell" },
    { name = "mypy" },
    { name = "ruff" },
]
test = [
    { name = "langchain-core" },
    { name = "langgraph", editable = "../langgraph" },
    { name = "langgraph-checkpoint", editable = "../checkpoint" },
    { name = "langgraph-checkpoint-postgres", editable = "../checkpoint-postgres" },
    { name = "langgraph-checkpoint-sqlite", editable = "../checkpoint-sqlite" },
    { name = "psycopg-binary" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watcher" },
    { name = "syrupy" },
]

[[package]]
name = "langgraph-sdk"
source = { editable = "../sdk-py" }
dependencies = [
    { name = "httpx" },
    { name = "orjson" },
]

[package.metadata]
requires-dist = [
    { name = "httpx", specifier = ">=0.25.2" },
    { name = "orjson", specifier = ">=3.10.1" },
]

[package.metadata.requires-dev]
dev = [
    { name = "codespell" },
    { name = "mypy" },
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watch" },
    { name = "ruff" },
]
lint = [
    { name = "codespell" },
    { name = "mypy" },
    { name = "ruff" },
]
test = [
    { name = "pytest" },
    { name = "pytest-asyncio" },
    { name = "pytest-mock" },
    { name = "pytest-watch" },
]

[[package]]
name = "langsmith"
version = "0.4.31"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "httpx" },
    { name = "orjson", marker = "platform_python_implementation != 'PyPy'" },
    { name = "packaging" },
    { name = "pydantic" },
    { name = "requests" },
    { name = "requests-toolbelt" },
    { name = "zstandard" },
]
sdist = { url = "https://files.pythonhosted.org/packages/55/f5/edbdf89a162ee025348b3b2080fb3b88f4a1040a5a186f32d34aca913994/langsmith-0.4.31.tar.gz", hash = "sha256:5fb3729e22bd9a225391936cb9d1080322e6c375bb776514af06b56d6c46ed3e", size = 959698, upload-time = "2025-09-25T04:18:19.55Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/3e/8e/e7a43d907a147e1f87eebdd6737483f9feba52a5d4b20f69d0bd6f2fa22f/langsmith-0.4.31-py3-none-any.whl", hash = "sha256:64f340bdead21defe5f4a6ca330c11073e35444989169f669508edf45a19025f", size = 386347, upload-time = "2025-09-25T04:18:16.69Z" },
]

[[package]]
name = "mypy"
version = "1.18.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "mypy-extensions" },
    { name = "pathspec" },
    { name = "tomli", marker = "python_full_version < '3.11'" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/c0/77/8f0d0001ffad290cef2f7f216f96c814866248a0b92a722365ed54648e7e/mypy-1.18.2.tar.gz", hash = "sha256:06a398102a5f203d7477b2923dda3634c36727fa5c237d8f859ef90c42a9924b", size = 3448846, upload-time = "2025-09-19T00:11:10.519Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/03/6f/657961a0743cff32e6c0611b63ff1c1970a0b482ace35b069203bf705187/mypy-1.18.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:c1eab0cf6294dafe397c261a75f96dc2c31bffe3b944faa24db5def4e2b0f77c", size = 12807973, upload-time = "2025-09-19T00:10:35.282Z" },
    { url = "https://files.pythonhosted.org/packages/10/e9/420822d4f661f13ca8900f5fa239b40ee3be8b62b32f3357df9a3045a08b/mypy-1.18.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:7a780ca61fc239e4865968ebc5240bb3bf610ef59ac398de9a7421b54e4a207e", size = 11896527, upload-time = "2025-09-19T00:10:55.791Z" },
    { url = "https://files.pythonhosted.org/packages/aa/73/a05b2bbaa7005f4642fcfe40fb73f2b4fb6bb44229bd585b5878e9a87ef8/mypy-1.18.2-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:448acd386266989ef11662ce3c8011fd2a7b632e0ec7d61a98edd8e27472225b", size = 12507004, upload-time = "2025-09-19T00:11:05.411Z" },
    { url = "https://files.pythonhosted.org/packages/4f/01/f6e4b9f0d031c11ccbd6f17da26564f3a0f3c4155af344006434b0a05a9d/mypy-1.18.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:f9e171c465ad3901dc652643ee4bffa8e9fef4d7d0eece23b428908c77a76a66", size = 13245947, upload-time = "2025-09-19T00:10:46.923Z" },
    { url = "https://files.pythonhosted.org/packages/d7/97/19727e7499bfa1ae0773d06afd30ac66a58ed7437d940c70548634b24185/mypy-1.18.2-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:592ec214750bc00741af1f80cbf96b5013d81486b7bb24cb052382c19e40b428", size = 13499217, upload-time = "2025-09-19T00:09:39.472Z" },
    { url = "https://files.pythonhosted.org/packages/9f/4f/90dc8c15c1441bf31cf0f9918bb077e452618708199e530f4cbd5cede6ff/mypy-1.18.2-cp310-cp310-win_amd64.whl", hash = "sha256:7fb95f97199ea11769ebe3638c29b550b5221e997c63b14ef93d2e971606ebed", size = 9766753, upload-time = "2025-09-19T00:10:49.161Z" },
    { url = "https://files.pythonhosted.org/packages/88/87/cafd3ae563f88f94eec33f35ff722d043e09832ea8530ef149ec1efbaf08/mypy-1.18.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:807d9315ab9d464125aa9fcf6d84fde6e1dc67da0b6f80e7405506b8ac72bc7f", size = 12731198, upload-time = "2025-09-19T00:09:44.857Z" },
    { url = "https://files.pythonhosted.org/packages/0f/e0/1e96c3d4266a06d4b0197ace5356d67d937d8358e2ee3ffac71faa843724/mypy-1.18.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:776bb00de1778caf4db739c6e83919c1d85a448f71979b6a0edd774ea8399341", size = 11817879, upload-time = "2025-09-19T00:09:47.131Z" },
    { url = "https://files.pythonhosted.org/packages/72/ef/0c9ba89eb03453e76bdac5a78b08260a848c7bfc5d6603634774d9cd9525/mypy-1.18.2-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:1379451880512ffce14505493bd9fe469e0697543717298242574882cf8cdb8d", size = 12427292, upload-time = "2025-09-19T00:10:22.472Z" },
    { url = "https://files.pythonhosted.org/packages/1a/52/ec4a061dd599eb8179d5411d99775bec2a20542505988f40fc2fee781068/mypy-1.18.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:1331eb7fd110d60c24999893320967594ff84c38ac6d19e0a76c5fd809a84c86", size = 13163750, upload-time = "2025-09-19T00:09:51.472Z" },
    { url = "https://files.pythonhosted.org/packages/c4/5f/2cf2ceb3b36372d51568f2208c021870fe7834cf3186b653ac6446511839/mypy-1.18.2-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:3ca30b50a51e7ba93b00422e486cbb124f1c56a535e20eff7b2d6ab72b3b2e37", size = 13351827, upload-time = "2025-09-19T00:09:58.311Z" },
    { url = "https://files.pythonhosted.org/packages/c8/7d/2697b930179e7277529eaaec1513f8de622818696857f689e4a5432e5e27/mypy-1.18.2-cp311-cp311-win_amd64.whl", hash = "sha256:664dc726e67fa54e14536f6e1224bcfce1d9e5ac02426d2326e2bb4e081d1ce8", size = 9757983, upload-time = "2025-09-19T00:10:09.071Z" },
    { url = "https://files.pythonhosted.org/packages/07/06/dfdd2bc60c66611dd8335f463818514733bc763e4760dee289dcc33df709/mypy-1.18.2-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:33eca32dd124b29400c31d7cf784e795b050ace0e1f91b8dc035672725617e34", size = 12908273, upload-time = "2025-09-19T00:10:58.321Z" },
    { url = "https://files.pythonhosted.org/packages/81/14/6a9de6d13a122d5608e1a04130724caf9170333ac5a924e10f670687d3eb/mypy-1.18.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:a3c47adf30d65e89b2dcd2fa32f3aeb5e94ca970d2c15fcb25e297871c8e4764", size = 11920910, upload-time = "2025-09-19T00:10:20.043Z" },
    { url = "https://files.pythonhosted.org/packages/5f/a9/b29de53e42f18e8cc547e38daa9dfa132ffdc64f7250e353f5c8cdd44bee/mypy-1.18.2-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:5d6c838e831a062f5f29d11c9057c6009f60cb294fea33a98422688181fe2893", size = 12465585, upload-time = "2025-09-19T00:10:33.005Z" },
    { url = "https://files.pythonhosted.org/packages/77/ae/6c3d2c7c61ff21f2bee938c917616c92ebf852f015fb55917fd6e2811db2/mypy-1.18.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:01199871b6110a2ce984bde85acd481232d17413868c9807e95c1b0739a58914", size = 13348562, upload-time = "2025-09-19T00:10:11.51Z" },
    { url = "https://files.pythonhosted.org/packages/4d/31/aec68ab3b4aebdf8f36d191b0685d99faa899ab990753ca0fee60fb99511/mypy-1.18.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:a2afc0fa0b0e91b4599ddfe0f91e2c26c2b5a5ab263737e998d6817874c5f7c8", size = 13533296, upload-time = "2025-09-19T00:10:06.568Z" },
    { url = "https://files.pythonhosted.org/packages/9f/83/abcb3ad9478fca3ebeb6a5358bb0b22c95ea42b43b7789c7fb1297ca44f4/mypy-1.18.2-cp312-cp312-win_amd64.whl", hash = "sha256:d8068d0afe682c7c4897c0f7ce84ea77f6de953262b12d07038f4d296d547074", size = 9828828, upload-time = "2025-09-19T00:10:28.203Z" },
    { url = "https://files.pythonhosted.org/packages/5f/04/7f462e6fbba87a72bc8097b93f6842499c428a6ff0c81dd46948d175afe8/mypy-1.18.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:07b8b0f580ca6d289e69209ec9d3911b4a26e5abfde32228a288eb79df129fcc", size = 12898728, upload-time = "2025-09-19T00:10:01.33Z" },
    { url = "https://files.pythonhosted.org/packages/99/5b/61ed4efb64f1871b41fd0b82d29a64640f3516078f6c7905b68ab1ad8b13/mypy-1.18.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:ed4482847168439651d3feee5833ccedbf6657e964572706a2adb1f7fa4dfe2e", size = 11910758, upload-time = "2025-09-19T00:10:42.607Z" },
    { url = "https://files.pythonhosted.org/packages/3c/46/d297d4b683cc89a6e4108c4250a6a6b717f5fa96e1a30a7944a6da44da35/mypy-1.18.2-cp313-cp313-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:c3ad2afadd1e9fea5cf99a45a822346971ede8685cc581ed9cd4d42eaf940986", size = 12475342, upload-time = "2025-09-19T00:11:00.371Z" },
    { url = "https://files.pythonhosted.org/packages/83/45/4798f4d00df13eae3bfdf726c9244bcb495ab5bd588c0eed93a2f2dd67f3/mypy-1.18.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:a431a6f1ef14cf8c144c6b14793a23ec4eae3db28277c358136e79d7d062f62d", size = 13338709, upload-time = "2025-09-19T00:11:03.358Z" },
    { url = "https://files.pythonhosted.org/packages/d7/09/479f7358d9625172521a87a9271ddd2441e1dab16a09708f056e97007207/mypy-1.18.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:7ab28cc197f1dd77a67e1c6f35cd1f8e8b73ed2217e4fc005f9e6a504e46e7ba", size = 13529806, upload-time = "2025-09-19T00:10:26.073Z" },
    { url = "https://files.pythonhosted.org/packages/71/cf/ac0f2c7e9d0ea3c75cd99dff7aec1c9df4a1376537cb90e4c882267ee7e9/mypy-1.18.2-cp313-cp313-win_amd64.whl", hash = "sha256:0e2785a84b34a72ba55fb5daf079a1003a34c05b22238da94fcae2bbe46f3544", size = 9833262, upload-time = "2025-09-19T00:10:40.035Z" },
    { url = "https://files.pythonhosted.org/packages/5a/0c/7d5300883da16f0063ae53996358758b2a2df2a09c72a5061fa79a1f5006/mypy-1.18.2-cp314-cp314-macosx_10_13_x86_64.whl", hash = "sha256:62f0e1e988ad41c2a110edde6c398383a889d95b36b3e60bcf155f5164c4fdce", size = 12893775, upload-time = "2025-09-19T00:10:03.814Z" },
    { url = "https://files.pythonhosted.org/packages/50/df/2cffbf25737bdb236f60c973edf62e3e7b4ee1c25b6878629e88e2cde967/mypy-1.18.2-cp314-cp314-macosx_11_0_arm64.whl", hash = "sha256:8795a039bab805ff0c1dfdb8cd3344642c2b99b8e439d057aba30850b8d3423d", size = 11936852, upload-time = "2025-09-19T00:10:51.631Z" },
    { url = "https://files.pythonhosted.org/packages/be/50/34059de13dd269227fb4a03be1faee6e2a4b04a2051c82ac0a0b5a773c9a/mypy-1.18.2-cp314-cp314-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:6ca1e64b24a700ab5ce10133f7ccd956a04715463d30498e64ea8715236f9c9c", size = 12480242, upload-time = "2025-09-19T00:11:07.955Z" },
    { url = "https://files.pythonhosted.org/packages/5b/11/040983fad5132d85914c874a2836252bbc57832065548885b5bb5b0d4359/mypy-1.18.2-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:d924eef3795cc89fecf6bedc6ed32b33ac13e8321344f6ddbf8ee89f706c05cb", size = 13326683, upload-time = "2025-09-19T00:09:55.572Z" },
    { url = "https://files.pythonhosted.org/packages/e9/ba/89b2901dd77414dd7a8c8729985832a5735053be15b744c18e4586e506ef/mypy-1.18.2-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:20c02215a080e3a2be3aa50506c67242df1c151eaba0dcbc1e4e557922a26075", size = 13514749, upload-time = "2025-09-19T00:10:44.827Z" },
    { url = "https://files.pythonhosted.org/packages/25/bc/cc98767cffd6b2928ba680f3e5bc969c4152bf7c2d83f92f5a504b92b0eb/mypy-1.18.2-cp314-cp314-win_amd64.whl", hash = "sha256:749b5f83198f1ca64345603118a6f01a4e99ad4bf9d103ddc5a3200cc4614adf", size = 9982959, upload-time = "2025-09-19T00:10:37.344Z" },
    { url = "https://files.pythonhosted.org/packages/87/e3/be76d87158ebafa0309946c4a73831974d4d6ab4f4ef40c3b53a385a66fd/mypy-1.18.2-py3-none-any.whl", hash = "sha256:22a1748707dd62b58d2ae53562ffc4d7f8bcc727e8ac7cbc69c053ddc874d47e", size = 2352367, upload-time = "2025-09-19T00:10:15.489Z" },
]

[[package]]
name = "mypy-extensions"
version = "1.1.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a2/6e/371856a3fb9d31ca8dac321cda606860fa4548858c0cc45d9d1d4ca2628b/mypy_extensions-1.1.0.tar.gz", hash = "sha256:52e68efc3284861e772bbcd66823fde5ae21fd2fdb51c62a211403730b916558", size = 6343, upload-time = "2025-04-22T14:54:24.164Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/79/7b/2c79738432f5c924bef5071f933bcc9efd0473bac3b4aa584a6f7c1c8df8/mypy_extensions-1.1.0-py3-none-any.whl", hash = "sha256:1be4cccdb0f2482337c4743e60421de3a356cd97508abadd57d47403e94f5505", size = 4963, upload-time = "2025-04-22T14:54:22.983Z" },
]

[[package]]
name = "orjson"
version = "3.11.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/be/4d/8df5f83256a809c22c4d6792ce8d43bb503be0fb7a8e4da9025754b09658/orjson-3.11.3.tar.gz", hash = "sha256:1c0603b1d2ffcd43a411d64797a19556ef76958aef1c182f22dc30860152a98a", size = 5482394, upload-time = "2025-08-26T17:46:43.171Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9b/64/4a3cef001c6cd9c64256348d4c13a7b09b857e3e1cbb5185917df67d8ced/orjson-3.11.3-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl", hash = "sha256:29cb1f1b008d936803e2da3d7cba726fc47232c45df531b29edf0b232dd737e7", size = 238600, upload-time = "2025-08-26T17:44:36.875Z" },
    { url = "https://files.pythonhosted.org/packages/10/ce/0c8c87f54f79d051485903dc46226c4d3220b691a151769156054df4562b/orjson-3.11.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:97dceed87ed9139884a55db8722428e27bd8452817fbf1869c58b49fecab1120", size = 123526, upload-time = "2025-08-26T17:44:39.574Z" },
    { url = "https://files.pythonhosted.org/packages/ef/d0/249497e861f2d438f45b3ab7b7b361484237414945169aa285608f9f7019/orjson-3.11.3-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:58533f9e8266cb0ac298e259ed7b4d42ed3fa0b78ce76860626164de49e0d467", size = 128075, upload-time = "2025-08-26T17:44:40.672Z" },
    { url = "https://files.pythonhosted.org/packages/e5/64/00485702f640a0fd56144042a1ea196469f4a3ae93681871564bf74fa996/orjson-3.11.3-cp310-cp310-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0c212cfdd90512fe722fa9bd620de4d46cda691415be86b2e02243242ae81873", size = 130483, upload-time = "2025-08-26T17:44:41.788Z" },
    { url = "https://files.pythonhosted.org/packages/64/81/110d68dba3909171bf3f05619ad0cf187b430e64045ae4e0aa7ccfe25b15/orjson-3.11.3-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:5ff835b5d3e67d9207343effb03760c00335f8b5285bfceefd4dc967b0e48f6a", size = 132539, upload-time = "2025-08-26T17:44:43.12Z" },
    { url = "https://files.pythonhosted.org/packages/79/92/dba25c22b0ddfafa1e6516a780a00abac28d49f49e7202eb433a53c3e94e/orjson-3.11.3-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f5aa4682912a450c2db89cbd92d356fef47e115dffba07992555542f344d301b", size = 135390, upload-time = "2025-08-26T17:44:44.199Z" },
    { url = "https://files.pythonhosted.org/packages/44/1d/ca2230fd55edbd87b58a43a19032d63a4b180389a97520cc62c535b726f9/orjson-3.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d7d18dd34ea2e860553a579df02041845dee0af8985dff7f8661306f95504ddf", size = 132966, upload-time = "2025-08-26T17:44:45.719Z" },
    { url = "https://files.pythonhosted.org/packages/6e/b9/96bbc8ed3e47e52b487d504bd6861798977445fbc410da6e87e302dc632d/orjson-3.11.3-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:d8b11701bc43be92ea42bd454910437b355dfb63696c06fe953ffb40b5f763b4", size = 131349, upload-time = "2025-08-26T17:44:46.862Z" },
    { url = "https://files.pythonhosted.org/packages/c4/3c/418fbd93d94b0df71cddf96b7fe5894d64a5d890b453ac365120daec30f7/orjson-3.11.3-cp310-cp310-musllinux_1_2_armv7l.whl", hash = "sha256:90368277087d4af32d38bd55f9da2ff466d25325bf6167c8f382d8ee40cb2bbc", size = 404087, upload-time = "2025-08-26T17:44:48.079Z" },
    { url = "https://files.pythonhosted.org/packages/5b/a9/2bfd58817d736c2f63608dec0c34857339d423eeed30099b126562822191/orjson-3.11.3-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:fd7ff459fb393358d3a155d25b275c60b07a2c83dcd7ea962b1923f5a1134569", size = 146067, upload-time = "2025-08-26T17:44:49.302Z" },
    { url = "https://files.pythonhosted.org/packages/33/ba/29023771f334096f564e48d82ed855a0ed3320389d6748a9c949e25be734/orjson-3.11.3-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:f8d902867b699bcd09c176a280b1acdab57f924489033e53d0afe79817da37e6", size = 135506, upload-time = "2025-08-26T17:44:50.558Z" },
    { url = "https://files.pythonhosted.org/packages/39/62/b5a1eca83f54cb3aa11a9645b8a22f08d97dbd13f27f83aae7c6666a0a05/orjson-3.11.3-cp310-cp310-win32.whl", hash = "sha256:bb93562146120bb51e6b154962d3dadc678ed0fce96513fa6bc06599bb6f6edc", size = 136352, upload-time = "2025-08-26T17:44:51.698Z" },
    { url = "https://files.pythonhosted.org/packages/e3/c0/7ebfaa327d9a9ed982adc0d9420dbce9a3fec45b60ab32c6308f731333fa/orjson-3.11.3-cp310-cp310-win_amd64.whl", hash = "sha256:976c6f1975032cc327161c65d4194c549f2589d88b105a5e3499429a54479770", size = 131539, upload-time = "2025-08-26T17:44:52.974Z" },
    { url = "https://files.pythonhosted.org/packages/cd/8b/360674cd817faef32e49276187922a946468579fcaf37afdfb6c07046e92/orjson-3.11.3-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl", hash = "sha256:9d2ae0cc6aeb669633e0124531f342a17d8e97ea999e42f12a5ad4adaa304c5f", size = 238238, upload-time = "2025-08-26T17:44:54.214Z" },
    { url = "https://files.pythonhosted.org/packages/05/3d/5fa9ea4b34c1a13be7d9046ba98d06e6feb1d8853718992954ab59d16625/orjson-3.11.3-cp311-cp311-macosx_15_0_arm64.whl", hash = "sha256:ba21dbb2493e9c653eaffdc38819b004b7b1b246fb77bfc93dc016fe664eac91", size = 127713, upload-time = "2025-08-26T17:44:55.596Z" },
    { url = "https://files.pythonhosted.org/packages/e5/5f/e18367823925e00b1feec867ff5f040055892fc474bf5f7875649ecfa586/orjson-3.11.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:00f1a271e56d511d1569937c0447d7dce5a99a33ea0dec76673706360a051904", size = 123241, upload-time = "2025-08-26T17:44:57.185Z" },
    { url = "https://files.pythonhosted.org/packages/0f/bd/3c66b91c4564759cf9f473251ac1650e446c7ba92a7c0f9f56ed54f9f0e6/orjson-3.11.3-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:b67e71e47caa6680d1b6f075a396d04fa6ca8ca09aafb428731da9b3ea32a5a6", size = 127895, upload-time = "2025-08-26T17:44:58.349Z" },
    { url = "https://files.pythonhosted.org/packages/82/b5/dc8dcd609db4766e2967a85f63296c59d4722b39503e5b0bf7fd340d387f/orjson-3.11.3-cp311-cp311-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d7d012ebddffcce8c85734a6d9e5f08180cd3857c5f5a3ac70185b43775d043d", size = 130303, upload-time = "2025-08-26T17:44:59.491Z" },
    { url = "https://files.pythonhosted.org/packages/48/c2/d58ec5fd1270b2aa44c862171891adc2e1241bd7dab26c8f46eb97c6c6f1/orjson-3.11.3-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:dd759f75d6b8d1b62012b7f5ef9461d03c804f94d539a5515b454ba3a6588038", size = 132366, upload-time = "2025-08-26T17:45:00.654Z" },
    { url = "https://files.pythonhosted.org/packages/73/87/0ef7e22eb8dd1ef940bfe3b9e441db519e692d62ed1aae365406a16d23d0/orjson-3.11.3-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6890ace0809627b0dff19cfad92d69d0fa3f089d3e359a2a532507bb6ba34efb", size = 135180, upload-time = "2025-08-26T17:45:02.424Z" },
    { url = "https://files.pythonhosted.org/packages/bb/6a/e5bf7b70883f374710ad74faf99bacfc4b5b5a7797c1d5e130350e0e28a3/orjson-3.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f9d4a5e041ae435b815e568537755773d05dac031fee6a57b4ba70897a44d9d2", size = 132741, upload-time = "2025-08-26T17:45:03.663Z" },
    { url = "https://files.pythonhosted.org/packages/bd/0c/4577fd860b6386ffaa56440e792af01c7882b56d2766f55384b5b0e9d39b/orjson-3.11.3-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:2d68bf97a771836687107abfca089743885fb664b90138d8761cce61d5625d55", size = 131104, upload-time = "2025-08-26T17:45:04.939Z" },
    { url = "https://files.pythonhosted.org/packages/66/4b/83e92b2d67e86d1c33f2ea9411742a714a26de63641b082bdbf3d8e481af/orjson-3.11.3-cp311-cp311-musllinux_1_2_armv7l.whl", hash = "sha256:bfc27516ec46f4520b18ef645864cee168d2a027dbf32c5537cb1f3e3c22dac1", size = 403887, upload-time = "2025-08-26T17:45:06.228Z" },
    { url = "https://files.pythonhosted.org/packages/6d/e5/9eea6a14e9b5ceb4a271a1fd2e1dec5f2f686755c0fab6673dc6ff3433f4/orjson-3.11.3-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:f66b001332a017d7945e177e282a40b6997056394e3ed7ddb41fb1813b83e824", size = 145855, upload-time = "2025-08-26T17:45:08.338Z" },
    { url = "https://files.pythonhosted.org/packages/45/78/8d4f5ad0c80ba9bf8ac4d0fc71f93a7d0dc0844989e645e2074af376c307/orjson-3.11.3-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:212e67806525d2561efbfe9e799633b17eb668b8964abed6b5319b2f1cfbae1f", size = 135361, upload-time = "2025-08-26T17:45:09.625Z" },
    { url = "https://files.pythonhosted.org/packages/0b/5f/16386970370178d7a9b438517ea3d704efcf163d286422bae3b37b88dbb5/orjson-3.11.3-cp311-cp311-win32.whl", hash = "sha256:6e8e0c3b85575a32f2ffa59de455f85ce002b8bdc0662d6b9c2ed6d80ab5d204", size = 136190, upload-time = "2025-08-26T17:45:10.962Z" },
    { url = "https://files.pythonhosted.org/packages/09/60/db16c6f7a41dd8ac9fb651f66701ff2aeb499ad9ebc15853a26c7c152448/orjson-3.11.3-cp311-cp311-win_amd64.whl", hash = "sha256:6be2f1b5d3dc99a5ce5ce162fc741c22ba9f3443d3dd586e6a1211b7bc87bc7b", size = 131389, upload-time = "2025-08-26T17:45:12.285Z" },
    { url = "https://files.pythonhosted.org/packages/3e/2a/bb811ad336667041dea9b8565c7c9faf2f59b47eb5ab680315eea612ef2e/orjson-3.11.3-cp311-cp311-win_arm64.whl", hash = "sha256:fafb1a99d740523d964b15c8db4eabbfc86ff29f84898262bf6e3e4c9e97e43e", size = 126120, upload-time = "2025-08-26T17:45:13.515Z" },
    { url = "https://files.pythonhosted.org/packages/3d/b0/a7edab2a00cdcb2688e1c943401cb3236323e7bfd2839815c6131a3742f4/orjson-3.11.3-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl", hash = "sha256:8c752089db84333e36d754c4baf19c0e1437012242048439c7e80eb0e6426e3b", size = 238259, upload-time = "2025-08-26T17:45:15.093Z" },
    { url = "https://files.pythonhosted.org/packages/e1/c6/ff4865a9cc398a07a83342713b5932e4dc3cb4bf4bc04e8f83dedfc0d736/orjson-3.11.3-cp312-cp312-macosx_15_0_arm64.whl", hash = "sha256:9b8761b6cf04a856eb544acdd82fc594b978f12ac3602d6374a7edb9d86fd2c2", size = 127633, upload-time = "2025-08-26T17:45:16.417Z" },
    { url = "https://files.pythonhosted.org/packages/6e/e6/e00bea2d9472f44fe8794f523e548ce0ad51eb9693cf538a753a27b8bda4/orjson-3.11.3-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8b13974dc8ac6ba22feaa867fc19135a3e01a134b4f7c9c28162fed4d615008a", size = 123061, upload-time = "2025-08-26T17:45:17.673Z" },
    { url = "https://files.pythonhosted.org/packages/54/31/9fbb78b8e1eb3ac605467cb846e1c08d0588506028b37f4ee21f978a51d4/orjson-3.11.3-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:f83abab5bacb76d9c821fd5c07728ff224ed0e52d7a71b7b3de822f3df04e15c", size = 127956, upload-time = "2025-08-26T17:45:19.172Z" },
    { url = "https://files.pythonhosted.org/packages/36/88/b0604c22af1eed9f98d709a96302006915cfd724a7ebd27d6dd11c22d80b/orjson-3.11.3-cp312-cp312-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:e6fbaf48a744b94091a56c62897b27c31ee2da93d826aa5b207131a1e13d4064", size = 130790, upload-time = "2025-08-26T17:45:20.586Z" },
    { url = "https://files.pythonhosted.org/packages/0e/9d/1c1238ae9fffbfed51ba1e507731b3faaf6b846126a47e9649222b0fd06f/orjson-3.11.3-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:bc779b4f4bba2847d0d2940081a7b6f7b5877e05408ffbb74fa1faf4a136c424", size = 132385, upload-time = "2025-08-26T17:45:22.036Z" },
    { url = "https://files.pythonhosted.org/packages/a3/b5/c06f1b090a1c875f337e21dd71943bc9d84087f7cdf8c6e9086902c34e42/orjson-3.11.3-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:bd4b909ce4c50faa2192da6bb684d9848d4510b736b0611b6ab4020ea6fd2d23", size = 135305, upload-time = "2025-08-26T17:45:23.4Z" },
    { url = "https://files.pythonhosted.org/packages/a0/26/5f028c7d81ad2ebbf84414ba6d6c9cac03f22f5cd0d01eb40fb2d6a06b07/orjson-3.11.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:524b765ad888dc5518bbce12c77c2e83dee1ed6b0992c1790cc5fb49bb4b6667", size = 132875, upload-time = "2025-08-26T17:45:25.182Z" },
    { url = "https://files.pythonhosted.org/packages/fe/d4/b8df70d9cfb56e385bf39b4e915298f9ae6c61454c8154a0f5fd7efcd42e/orjson-3.11.3-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:84fd82870b97ae3cdcea9d8746e592b6d40e1e4d4527835fc520c588d2ded04f", size = 130940, upload-time = "2025-08-26T17:45:27.209Z" },
    { url = "https://files.pythonhosted.org/packages/da/5e/afe6a052ebc1a4741c792dd96e9f65bf3939d2094e8b356503b68d48f9f5/orjson-3.11.3-cp312-cp312-musllinux_1_2_armv7l.whl", hash = "sha256:fbecb9709111be913ae6879b07bafd4b0785b44c1eb5cac8ac76da048b3885a1", size = 403852, upload-time = "2025-08-26T17:45:28.478Z" },
    { url = "https://files.pythonhosted.org/packages/f8/90/7bbabafeb2ce65915e9247f14a56b29c9334003536009ef5b122783fe67e/orjson-3.11.3-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:9dba358d55aee552bd868de348f4736ca5a4086d9a62e2bfbbeeb5629fe8b0cc", size = 146293, upload-time = "2025-08-26T17:45:29.86Z" },
    { url = "https://files.pythonhosted.org/packages/27/b3/2d703946447da8b093350570644a663df69448c9d9330e5f1d9cce997f20/orjson-3.11.3-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:eabcf2e84f1d7105f84580e03012270c7e97ecb1fb1618bda395061b2a84a049", size = 135470, upload-time = "2025-08-26T17:45:31.243Z" },
    { url = "https://files.pythonhosted.org/packages/38/70/b14dcfae7aff0e379b0119c8a812f8396678919c431efccc8e8a0263e4d9/orjson-3.11.3-cp312-cp312-win32.whl", hash = "sha256:3782d2c60b8116772aea8d9b7905221437fdf53e7277282e8d8b07c220f96cca", size = 136248, upload-time = "2025-08-26T17:45:32.567Z" },
    { url = "https://files.pythonhosted.org/packages/35/b8/9e3127d65de7fff243f7f3e53f59a531bf6bb295ebe5db024c2503cc0726/orjson-3.11.3-cp312-cp312-win_amd64.whl", hash = "sha256:79b44319268af2eaa3e315b92298de9a0067ade6e6003ddaef72f8e0bedb94f1", size = 131437, upload-time = "2025-08-26T17:45:34.949Z" },
    { url = "https://files.pythonhosted.org/packages/51/92/a946e737d4d8a7fd84a606aba96220043dcc7d6988b9e7551f7f6d5ba5ad/orjson-3.11.3-cp312-cp312-win_arm64.whl", hash = "sha256:0e92a4e83341ef79d835ca21b8bd13e27c859e4e9e4d7b63defc6e58462a3710", size = 125978, upload-time = "2025-08-26T17:45:36.422Z" },
    { url = "https://files.pythonhosted.org/packages/fc/79/8932b27293ad35919571f77cb3693b5906cf14f206ef17546052a241fdf6/orjson-3.11.3-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl", hash = "sha256:af40c6612fd2a4b00de648aa26d18186cd1322330bd3a3cc52f87c699e995810", size = 238127, upload-time = "2025-08-26T17:45:38.146Z" },
    { url = "https://files.pythonhosted.org/packages/1c/82/cb93cd8cf132cd7643b30b6c5a56a26c4e780c7a145db6f83de977b540ce/orjson-3.11.3-cp313-cp313-macosx_15_0_arm64.whl", hash = "sha256:9f1587f26c235894c09e8b5b7636a38091a9e6e7fe4531937534749c04face43", size = 127494, upload-time = "2025-08-26T17:45:39.57Z" },
    { url = "https://files.pythonhosted.org/packages/a4/b8/2d9eb181a9b6bb71463a78882bcac1027fd29cf62c38a40cc02fc11d3495/orjson-3.11.3-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:61dcdad16da5bb486d7227a37a2e789c429397793a6955227cedbd7252eb5a27", size = 123017, upload-time = "2025-08-26T17:45:40.876Z" },
    { url = "https://files.pythonhosted.org/packages/b4/14/a0e971e72d03b509190232356d54c0f34507a05050bd026b8db2bf2c192c/orjson-3.11.3-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:11c6d71478e2cbea0a709e8a06365fa63da81da6498a53e4c4f065881d21ae8f", size = 127898, upload-time = "2025-08-26T17:45:42.188Z" },
    { url = "https://files.pythonhosted.org/packages/8e/af/dc74536722b03d65e17042cc30ae586161093e5b1f29bccda24765a6ae47/orjson-3.11.3-cp313-cp313-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ff94112e0098470b665cb0ed06efb187154b63649403b8d5e9aedeb482b4548c", size = 130742, upload-time = "2025-08-26T17:45:43.511Z" },
    { url = "https://files.pythonhosted.org/packages/62/e6/7a3b63b6677bce089fe939353cda24a7679825c43a24e49f757805fc0d8a/orjson-3.11.3-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ae8b756575aaa2a855a75192f356bbda11a89169830e1439cfb1a3e1a6dde7be", size = 132377, upload-time = "2025-08-26T17:45:45.525Z" },
    { url = "https://files.pythonhosted.org/packages/fc/cd/ce2ab93e2e7eaf518f0fd15e3068b8c43216c8a44ed82ac2b79ce5cef72d/orjson-3.11.3-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c9416cc19a349c167ef76135b2fe40d03cea93680428efee8771f3e9fb66079d", size = 135313, upload-time = "2025-08-26T17:45:46.821Z" },
    { url = "https://files.pythonhosted.org/packages/d0/b4/f98355eff0bd1a38454209bbc73372ce351ba29933cb3e2eba16c04b9448/orjson-3.11.3-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b822caf5b9752bc6f246eb08124c3d12bf2175b66ab74bac2ef3bbf9221ce1b2", size = 132908, upload-time = "2025-08-26T17:45:48.126Z" },
    { url = "https://files.pythonhosted.org/packages/eb/92/8f5182d7bc2a1bed46ed960b61a39af8389f0ad476120cd99e67182bfb6d/orjson-3.11.3-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:414f71e3bdd5573893bf5ecdf35c32b213ed20aa15536fe2f588f946c318824f", size = 130905, upload-time = "2025-08-26T17:45:49.414Z" },
    { url = "https://files.pythonhosted.org/packages/1a/60/c41ca753ce9ffe3d0f67b9b4c093bdd6e5fdb1bc53064f992f66bb99954d/orjson-3.11.3-cp313-cp313-musllinux_1_2_armv7l.whl", hash = "sha256:828e3149ad8815dc14468f36ab2a4b819237c155ee1370341b91ea4c8672d2ee", size = 403812, upload-time = "2025-08-26T17:45:51.085Z" },
    { url = "https://files.pythonhosted.org/packages/dd/13/e4a4f16d71ce1868860db59092e78782c67082a8f1dc06a3788aef2b41bc/orjson-3.11.3-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:ac9e05f25627ffc714c21f8dfe3a579445a5c392a9c8ae7ba1d0e9fb5333f56e", size = 146277, upload-time = "2025-08-26T17:45:52.851Z" },
    { url = "https://files.pythonhosted.org/packages/8d/8b/bafb7f0afef9344754a3a0597a12442f1b85a048b82108ef2c956f53babd/orjson-3.11.3-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:e44fbe4000bd321d9f3b648ae46e0196d21577cf66ae684a96ff90b1f7c93633", size = 135418, upload-time = "2025-08-26T17:45:54.806Z" },
    { url = "https://files.pythonhosted.org/packages/60/d4/bae8e4f26afb2c23bea69d2f6d566132584d1c3a5fe89ee8c17b718cab67/orjson-3.11.3-cp313-cp313-win32.whl", hash = "sha256:2039b7847ba3eec1f5886e75e6763a16e18c68a63efc4b029ddf994821e2e66b", size = 136216, upload-time = "2025-08-26T17:45:57.182Z" },
    { url = "https://files.pythonhosted.org/packages/88/76/224985d9f127e121c8cad882cea55f0ebe39f97925de040b75ccd4b33999/orjson-3.11.3-cp313-cp313-win_amd64.whl", hash = "sha256:29be5ac4164aa8bdcba5fa0700a3c9c316b411d8ed9d39ef8a882541bd452fae", size = 131362, upload-time = "2025-08-26T17:45:58.56Z" },
    { url = "https://files.pythonhosted.org/packages/e2/cf/0dce7a0be94bd36d1346be5067ed65ded6adb795fdbe3abd234c8d576d01/orjson-3.11.3-cp313-cp313-win_arm64.whl", hash = "sha256:18bd1435cb1f2857ceb59cfb7de6f92593ef7b831ccd1b9bfb28ca530e539dce", size = 125989, upload-time = "2025-08-26T17:45:59.95Z" },
    { url = "https://files.pythonhosted.org/packages/ef/77/d3b1fef1fc6aaeed4cbf3be2b480114035f4df8fa1a99d2dac1d40d6e924/orjson-3.11.3-cp314-cp314-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl", hash = "sha256:cf4b81227ec86935568c7edd78352a92e97af8da7bd70bdfdaa0d2e0011a1ab4", size = 238115, upload-time = "2025-08-26T17:46:01.669Z" },
    { url = "https://files.pythonhosted.org/packages/e4/6d/468d21d49bb12f900052edcfbf52c292022d0a323d7828dc6376e6319703/orjson-3.11.3-cp314-cp314-macosx_15_0_arm64.whl", hash = "sha256:bc8bc85b81b6ac9fc4dae393a8c159b817f4c2c9dee5d12b773bddb3b95fc07e", size = 127493, upload-time = "2025-08-26T17:46:03.466Z" },
    { url = "https://files.pythonhosted.org/packages/67/46/1e2588700d354aacdf9e12cc2d98131fb8ac6f31ca65997bef3863edb8ff/orjson-3.11.3-cp314-cp314-manylinux_2_34_aarch64.whl", hash = "sha256:88dcfc514cfd1b0de038443c7b3e6a9797ffb1b3674ef1fd14f701a13397f82d", size = 122998, upload-time = "2025-08-26T17:46:04.803Z" },
    { url = "https://files.pythonhosted.org/packages/3b/94/11137c9b6adb3779f1b34fd98be51608a14b430dbc02c6d41134fbba484c/orjson-3.11.3-cp314-cp314-manylinux_2_34_x86_64.whl", hash = "sha256:d61cd543d69715d5fc0a690c7c6f8dcc307bc23abef9738957981885f5f38229", size = 132915, upload-time = "2025-08-26T17:46:06.237Z" },
    { url = "https://files.pythonhosted.org/packages/10/61/dccedcf9e9bcaac09fdabe9eaee0311ca92115699500efbd31950d878833/orjson-3.11.3-cp314-cp314-musllinux_1_2_aarch64.whl", hash = "sha256:2b7b153ed90ababadbef5c3eb39549f9476890d339cf47af563aea7e07db2451", size = 130907, upload-time = "2025-08-26T17:46:07.581Z" },
    { url = "https://files.pythonhosted.org/packages/0e/fd/0e935539aa7b08b3ca0f817d73034f7eb506792aae5ecc3b7c6e679cdf5f/orjson-3.11.3-cp314-cp314-musllinux_1_2_armv7l.whl", hash = "sha256:7909ae2460f5f494fecbcd10613beafe40381fd0316e35d6acb5f3a05bfda167", size = 403852, upload-time = "2025-08-26T17:46:08.982Z" },
    { url = "https://files.pythonhosted.org/packages/4a/2b/50ae1a5505cd1043379132fdb2adb8a05f37b3e1ebffe94a5073321966fd/orjson-3.11.3-cp314-cp314-musllinux_1_2_i686.whl", hash = "sha256:2030c01cbf77bc67bee7eef1e7e31ecf28649353987775e3583062c752da0077", size = 146309, upload-time = "2025-08-26T17:46:10.576Z" },
    { url = "https://files.pythonhosted.org/packages/cd/1d/a473c158e380ef6f32753b5f39a69028b25ec5be331c2049a2201bde2e19/orjson-3.11.3-cp314-cp314-musllinux_1_2_x86_64.whl", hash = "sha256:a0169ebd1cbd94b26c7a7ad282cf5c2744fce054133f959e02eb5265deae1872", size = 135424, upload-time = "2025-08-26T17:46:12.386Z" },
    { url = "https://files.pythonhosted.org/packages/da/09/17d9d2b60592890ff7382e591aa1d9afb202a266b180c3d4049b1ec70e4a/orjson-3.11.3-cp314-cp314-win32.whl", hash = "sha256:0c6d7328c200c349e3a4c6d8c83e0a5ad029bdc2d417f234152bf34842d0fc8d", size = 136266, upload-time = "2025-08-26T17:46:13.853Z" },
    { url = "https://files.pythonhosted.org/packages/15/58/358f6846410a6b4958b74734727e582ed971e13d335d6c7ce3e47730493e/orjson-3.11.3-cp314-cp314-win_amd64.whl", hash = "sha256:317bbe2c069bbc757b1a2e4105b64aacd3bc78279b66a6b9e51e846e4809f804", size = 131351, upload-time = "2025-08-26T17:46:15.27Z" },
    { url = "https://files.pythonhosted.org/packages/28/01/d6b274a0635be0468d4dbd9cafe80c47105937a0d42434e805e67cd2ed8b/orjson-3.11.3-cp314-cp314-win_arm64.whl", hash = "sha256:e8f6a7a27d7b7bec81bd5924163e9af03d49bbb63013f107b48eb5d16db711bc", size = 125985, upload-time = "2025-08-26T17:46:16.67Z" },
]

[[package]]
name = "ormsgpack"
version = "1.12.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/6c/67/d5ef41c3b4a94400be801984ef7c7fc9623e1a82b643e74eeec367e7462b/ormsgpack-1.12.0.tar.gz", hash = "sha256:94be818fdbb0285945839b88763b269987787cb2f7ef280cad5d6ec815b7e608", size = 49959, upload-time = "2025-11-04T18:30:10.083Z" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/4d/0c/8f45fcd22c95190b05d4fba71375d8f783a9e3b0b6aaf476812b693e3868/ormsgpack-1.12.0-cp310-cp310-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl", hash = "sha256:e08904c232358b94a682ccfbb680bc47d3fd5c424bb7dccb65974dd20c95e8e1", size = 369156, upload-time = "2025-11-04T18:29:17.629Z" },
    { url = "https://files.pythonhosted.org/packages/d2/f8/c7adc093d4ceb05e38786906815f868210f808326c27f8124b4d9466a26b/ormsgpack-1.12.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b9ed7a4b0037d69c8ba7e670e03ee65ae8d5c5114a409e73c5770d7fb5e4b895", size = 195743, upload-time = "2025-11-04T18:29:18.964Z" },
    { url = "https://files.pythonhosted.org/packages/fe/b8/bf002648fa6c150ed6157837b00303edafb35f65c352429463f83214de18/ormsgpack-1.12.0-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:db2928525b684f3f2af0367aef7ae8d20cde37fc5349c700017129d493a755aa", size = 206472, upload-time = "2025-11-04T18:29:19.951Z" },
    { url = "https://files.pythonhosted.org/packages/23/d6/1f445947c95a931bb189b7864a3f9dcbeebe7dcbc1b3c7387427b3779228/ormsgpack-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:45f911d9c5b23d11e49ff03fc8f9566745a2b1a7d9033733a1c0a2fa9301cd60", size = 207959, upload-time = "2025-11-04T18:29:21.282Z" },
    { url = "https://files.pythonhosted.org/packages/5c/9c/dd8ccd7553a5c1d0b4b69a0541611983a2f9bc2e8c5708a4bfffc0100468/ormsgpack-1.12.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:98c54ae6fd682b2aceb264505af9b2255f3df9d84e6e4369bc44d2110f1f311d", size = 377659, upload-time = "2025-11-04T18:29:22.561Z" },
    { url = "https://files.pythonhosted.org/packages/3d/08/3282d8f6330e742d4cdbcfbe2c100b403ae5526ae82a1c1b6a11b7967e37/ormsgpack-1.12.0-cp310-cp310-musllinux_1_2_armv7l.whl", hash = "sha256:857ab987c3502de08258cc4baf0e87267cb2c80931601084e13df3c355b1ab9d", size = 471391, upload-time = "2025-11-04T18:29:23.663Z" },
    { url = "https://files.pythonhosted.org/packages/18/d4/94a2fbfd4837754bda7a099b6a23b9d40aba9e76e1af8b8fb8133612eb54/ormsgpack-1.12.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:27579d45dc502ee736238e1024559cb0a01aa72a3b68827448b8edf6a2dcdc9c", size = 381501, upload-time = "2025-11-04T18:29:24.771Z" },
    { url = "https://files.pythonhosted.org/packages/d8/c6/1a9fa122cb5deb10b067bbaa43165b12291a914cc0ce364988ff17bbf405/ormsgpack-1.12.0-cp310-cp310-win_amd64.whl", hash = "sha256:c78379d054760875540cf2e81f28da1bb78d09fda3eabdbeb6c53b3e297158cb", size = 112715, upload-time = "2025-11-04T18:29:26.016Z" },
    { url = "https://files.pythonhosted.org/packages/1a/ba/3cae83cf36420c1c8dd294f16c852c03313aafe2439a165c4c6ac611b1d0/ormsgpack-1.12.0-cp311-cp311-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl", hash = "sha256:c40d86d77391b18dd34de5295e3de2b8ad818bcab9c9def4121c8ec5c9714ae4", size = 369159, upload-time = "2025-11-04T18:29:27.057Z" },
